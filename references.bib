@misc{miller_truncated_2021,
    title = {Truncated {Marginal} {Neural} {Ratio} {Estimation}},
    url = {http://arxiv.org/abs/2107.01214},
    abstract = {Parametric stochastic simulators are ubiquitous in science, often featuring high-dimensional input parameters and/or an intractable likelihood. Performing Bayesian parameter inference in this context can be challenging. We present a neural simulation-based inference algorithm which simultaneously offers simulation efficiency and fast empirical posterior testability, which is unique among modern algorithms. Our approach is simulation efficient by simultaneously estimating low-dimensional marginal posteriors instead of the joint posterior and by proposing simulations targeted to an observation of interest via a prior suitably truncated by an indicator function. Furthermore, by estimating a locally amortized posterior our algorithm enables efficient empirical tests of the robustness of the inference results. Since scientists cannot access the ground truth, these tests are necessary for trusting inference in real-world applications. We perform experiments on a marginalized version of the simulation-based inference benchmark and two complex and narrow posteriors, highlighting the simulator efficiency of our algorithm as well as the quality of the estimated marginal posteriors.},
    urldate = {2023-02-02},
    author = {Miller, Benjamin Kurt and Cole, Alex and Forré, Patrick and Louppe, Gilles and Weniger, Christoph},
    month = jun,
    year = {2021},
    doi = {10.5281/zenodo.5043706},
    note = {arXiv:2107.01214 [astro-ph, physics:hep-ph, stat]},
    keywords = {Astrophysics - Instrumentation and Methods for Astrophysics, Computer Science - Machine Learning, High Energy Physics - Phenomenology, Statistics - Machine Learning, cited, done},
}
@article{beck_efficient_2022,
    title = {Efficient identification of informative features in simulation-based inference},
    volume = {35},
    url = {https://proceedings.neurips.cc/paper_files/paper/2022/hash/7a7f6cc5dc2a84fb4edf0feb8e5cfd50-Abstract-Conference.html},
    language = {en},
    urldate = {2024-10-18},
    journal = {Advances in Neural Information Processing Systems},
    author = {Beck, Jonas and Deistler, Michael and Bernaerts, Yves and Macke, Jakob H. and Berens, Philipp},
    month = dec,
    year = {2022},
    pages = {19260--19273},
}
@article{wunsch_optimal_2021,
    title = {Optimal statistical inference in the presence of systematic uncertainties using neural network optimization based on binned {Poisson} likelihoods with nuisance parameters},
    volume = {5},
    issn = {2510-2036, 2510-2044},
    url = {http://arxiv.org/abs/2003.07186},
    doi = {10.1007/s41781-020-00049-5},
    abstract = {Data analysis in science, e.g., high-energy particle physics, is often subject to an intractable likelihood if the observables and observations span a high-dimensional input space. Typically the problem is solved by reducing the dimensionality using feature engineering and histograms, whereby the latter technique allows to build the likelihood using Poisson statistics. However, in the presence of systematic uncertainties represented by nuisance parameters in the likelihood, the optimal dimensionality reduction with a minimal loss of information about the parameters of interest is not known. This work presents a novel strategy to construct the dimensionality reduction with neural networks for feature engineering and a differential formulation of histograms so that the full workflow can be optimized with the result of the statistical inference, e.g., the variance of a parameter of interest, as objective. We discuss how this approach results in an estimate of the parameters of interest that is close to optimal and the applicability of the technique is demonstrated with a simple example based on pseudo-experiments and a more complex example from high-energy particle physics.},
    number = {1},
    urldate = {2023-03-29},
    journal = {Computing and Software for Big Science},
    author = {Wunsch, Stefan and Jörger, Simon and Wolf, Roger and Quast, Günter},
    month = dec,
    year = {2021},
    note = {arXiv:2003.07186 [physics, stat]},
    keywords = {Physics - Data Analysis, Statistics and Probability, Statistics - Machine Learning},
    pages = {4},
}
@article{rubin_bayesianly_1984,
    title = {Bayesianly {Justifiable} and {Relevant} {Frequency} {Calculations} for the {Applied} {Statistician}},
    volume = {12},
    issn = {00905364, 21688966},
    url = {http://www.jstor.org/stable/2240995},
    abstract = {[A common reaction among applied statisticians is that the Bayesian statistician's energies in an applied problem must be directed at the a priori elicitation of one model specification from which an optimal design and all inferences follow automatically by applying Bayes's theorem to calculate conditional distributions of unknowns given knowns. I feel, however, that the applied Bayesian statistician's tool-kit should be more extensive and include tools that may be usefully labeled frequency calculations. Three types of Bayesianly justifiable and relevant frequency calculations are presented using examples to convey their use for the applied statistician.]},
    number = {4},
    urldate = {2025-08-05},
    journal = {The Annals of Statistics},
    author = {Rubin, Donald B.},
    year = {1984},
    note = {Publisher: Institute of Mathematical Statistics},
    pages = {1151--1172},
}
@article{dawid_well-calibrated_1982,
    title = {The {Well}-{Calibrated} {Bayesian}},
    volume = {77},
    issn = {0162-1459},
    url = {https://www.tandfonline.com/doi/abs/10.1080/01621459.1982.10477856},
    doi = {10.1080/01621459.1982.10477856},
    abstract = {Suppose that a forecaster sequentially assigns probabilities to events. He is well calibrated if, for example, of those events to which he assigns a probability 30 percent, the long-run proportion that actually occurs turns out to be 30 percent. We prove a theorem to the effect that a coherent Bayesian expects to be well calibrated, and consider its destructive implications for the theory of coherence.},
    number = {379},
    urldate = {2025-08-05},
    journal = {Journal of the American Statistical Association},
    author = {Dawid, A. P.},
    month = sep,
    year = {1982},
    note = {Publisher: ASA Website
\_eprint: https://www.tandfonline.com/doi/pdf/10.1080/01621459.1982.10477856},
    keywords = {Calibration, Coherence, Martingale, Probability forecasting, Subjectivism, Weather forecasting},
    pages = {605--610},
}
@article{pritchard_population_1999,
    title = {Population growth of human {Y} chromosomes: a study of {Y} chromosome microsatellites},
    volume = {16},
    issn = {0737-4038},
    shorttitle = {Population growth of human {Y} chromosomes},
    doi = {10.1093/oxfordjournals.molbev.a026091},
    abstract = {We use variation at a set of eight human Y chromosome microsatellite loci to investigate the demographic history of the Y chromosome. Instead of assuming a population of constant size, as in most of the previous work on the Y chromosome, we consider a model which permits a period of recent population growth. We show that for most of the populations in our sample this model fits the data far better than a model with no growth. We estimate the demographic parameters of this model for each population and also the time to the most recent common ancestor. Since there is some uncertainty about the details of the microsatellite mutation process, we consider several plausible mutation schemes and estimate the variance in mutation size simultaneously with the demographic parameters of interest. Our finding of a recent common ancestor (probably in the last 120,000 years), coupled with a strong signal of demographic expansion in all populations, suggests either a recent human expansion from a small ancestral population, or natural selection acting on the Y chromosome.},
    language = {eng},
    number = {12},
    journal = {Molecular Biology and Evolution},
    author = {Pritchard, J. K. and Seielstad, M. T. and Perez-Lezaun, A. and Feldman, M. W.},
    month = dec,
    year = {1999},
    pmid = {10605120},
    keywords = {Data Interpretation, Statistical, Evolution, Molecular, Genetic Variation, Geography, Humans, Microsatellite Repeats, Mutation, Sequence Analysis, DNA, Y Chromosome},
    pages = {1791--1798},
}
@article{beaumont_approximate_2002,
    title = {Approximate {Bayesian} {Computation} in {Population} {Genetics}},
    volume = {162},
    issn = {1943-2631},
    url = {https://doi.org/10.1093/genetics/162.4.2025},
    doi = {10.1093/genetics/162.4.2025},
    abstract = {We propose a new method for approximate Bayesian statistical inference on the basis of summary statistics. The method is suited to complex problems that arise in population genetics, extending ideas developed in this setting by earlier authors. Properties of the posterior distribution of a parameter, such as its mean or density curve, are approximated without explicit likelihood calculations. This is achieved by fitting a local-linear regression of simulated parameter values on simulated summary statistics, and then substituting the observed summary statistics into the regression equation. The method combines many of the advantages of Bayesian statistical inference with the computational efficiency of methods based on summary statistics. A key advantage of the method is that the nuisance parameters are automatically integrated out in the simulation step, so that the large numbers of nuisance parameters that arise in population genetics problems can be handled without difficulty. Simulation results indicate computational and statistical efficiency that compares favorably with those of alternative methods previously proposed in the literature. We also compare the relative efficiency of inferences obtained using methods based on summary statistics with those obtained directly from the data using MCMC.},
    number = {4},
    urldate = {2025-08-05},
    journal = {Genetics},
    author = {Beaumont, Mark A and Zhang, Wenyang and Balding, David J},
    month = dec,
    year = {2002},
    pages = {2025--2035},
}
@techreport{marin_approximate_2011,
    title = {Approximate {Bayesian} {Computational} methods},
    url = {http://arxiv.org/abs/1101.0955},
    abstract = {Also known as likelihood-free methods, approximate Bayesian computational (ABC) methods have appeared in the past ten years as the most satisfactory approach to untractable likelihood problems, first in genetics then in a broader spectrum of applications. However, these methods suffer to some degree from calibration difficulties that make them rather volatile in their implementation and thus render them suspicious to the users of more traditional Monte Carlo methods. In this survey, we study the various improvements and extensions made to the original ABC algorithm over the recent years.},
    number = {arXiv:1101.0955},
    urldate = {2022-07-13},
    institution = {arXiv},
    author = {Marin, Jean-Michel and Pudlo, Pierre and Robert, Christian P. and Ryder, Robin},
    month = may,
    year = {2011},
    note = {arXiv:1101.0955 [stat]
type: article},
    keywords = {Statistics - Computation},
}
@article{diggle_monte_1984,
    title = {Monte {Carlo} {Methods} of {Inference} for {Implicit} {Statistical} {Models}},
    volume = {46},
    issn = {0035-9246},
    url = {https://doi.org/10.1111/j.2517-6161.1984.tb01290.x},
    doi = {10.1111/j.2517-6161.1984.tb01290.x},
    abstract = {A prescribed statistical model is a parametric specification of the distribution of a random vector, whilst an implicit statistical model is one defined at a more fundamental level in terms of a generating stochastic mechanism. This paper develops methods of inference which can be used for implicit statistical models whose distribution theory is intractable. The kernel method of probability density estimation is advocated for estimating a log-likelihood from simulations of such a model. The development and testing of an algorithm for maximizing this estimated log-likelihood function is described. An illustrative example involving a stochastic model for quantal response assays is given. Possible applications of the maximization algorithm to ad hoc methods of parameter estimation are noted briefly, and illustrated by an example involving a model for the spatial pattern of displaced amacrine cells in the retina of a rabbit.},
    number = {2},
    urldate = {2025-08-05},
    journal = {Journal of the Royal Statistical Society: Series B (Methodological)},
    author = {Diggle, Peter J. and Gratton, Richard J.},
    month = jan,
    year = {1984},
    pages = {193--212},
}
@misc{mohamed_learning_2017,
    title = {Learning in {Implicit} {Generative} {Models}},
    url = {http://arxiv.org/abs/1610.03483},
    doi = {10.48550/arXiv.1610.03483},
    abstract = {Generative adversarial networks (GANs) provide an algorithmic framework for constructing generative models with several appealing properties: they do not require a likelihood function to be specified, only a generating procedure; they provide samples that are sharp and compelling; and they allow us to harness our knowledge of building highly accurate neural network classifiers. Here, we develop our understanding of GANs with the aim of forming a rich view of this growing area of machine learning---to build connections to the diverse set of statistical thinking on this topic, of which much can be gained by a mutual exchange of ideas. We frame GANs within the wider landscape of algorithms for learning in implicit generative models--models that only specify a stochastic procedure with which to generate data--and relate these ideas to modelling problems in related fields, such as econometrics and approximate Bayesian computation. We develop likelihood-free inference methods and highlight hypothesis testing as a principle for learning in implicit generative models, using which we are able to derive the objective function used by GANs, and many other related objectives. The testing viewpoint directs our focus to the general problem of density ratio estimation. There are four approaches for density ratio estimation, one of which is a solution using classifiers to distinguish real from generated data. Other approaches such as divergence minimisation and moment matching have also been explored in the GAN literature, and we synthesise these views to form an understanding in terms of the relationships between them and the wider literature, highlighting avenues for future exploration and cross-pollination.},
    urldate = {2025-08-05},
    publisher = {arXiv},
    author = {Mohamed, Shakir and Lakshminarayanan, Balaji},
    month = feb,
    year = {2017},
    note = {arXiv:1610.03483 [stat]},
    keywords = {Computer Science - Machine Learning, Statistics - Computation, Statistics - Machine Learning},
}
@book{raiffa_applied_1961,
    title = {Applied {Statistical} {Decision} {Theory}},
    language = {en},
    publisher = {Division of Research, Graduate School of Business Administration, Harvard University},
    author = {Raiffa, Howard and Schlaifer, Robert},
    year = {1961},
    note = {Google-Books-ID: SpO0KFcFQDsC},
}
@article{metropolis_equation_1953,
    title = {Equation of {State} {Calculations} by {Fast} {Computing} {Machines}},
    volume = {21},
    issn = {0021-9606},
    url = {https://ui.adsabs.harvard.edu/abs/1953JChPh..21.1087M/abstract},
    doi = {10.1063/1.1699114},
    abstract = {A general method, suitable for fast computing machines, for investigating such properties as equations of state for substances consisting of interacting individual molecules is described. The method consists of a modified Monte Carlo integration over configuration space. Results for the two-dimensional rigid-sphere system have been obtained on the Los Alamos MANIAC and are presented here. These results are compared to the free volume equation of state and to a four-term virial coefficient expansion.},
    language = {en},
    number = {6},
    urldate = {2025-08-05},
    journal = {Journal of Chemical Physics},
    author = {Metropolis, Nicholas and Rosenbluth, Arianna W. and Rosenbluth, Marshall N. and Teller, Augusta H. and Teller, Edward},
    month = jun,
    year = {1953},
    pages = {1087--1092},
}
@article{hastings_monte_1970,
    title = {Monte {Carlo} {Sampling} {Methods} {Using} {Markov} {Chains} and {Their} {Applications}},
    volume = {57},
    issn = {0006-3444},
    url = {https://www.jstor.org/stable/2334940},
    doi = {10.2307/2334940},
    abstract = {A generalization of the sampling method introduced by Metropolis et al. (1953) is presented along with an exposition of the relevant theory, techniques of application and methods and difficulties of assessing the error in Monte Carlo estimates. Examples of the methods, including the generation of random orthogonal matrices and potential applications of the methods to numerical problems arising in statistics, are discussed.},
    number = {1},
    urldate = {2025-08-05},
    journal = {Biometrika},
    author = {Hastings, W. K.},
    year = {1970},
    note = {Publisher: [Oxford University Press, Biometrika Trust]},
    pages = {97--109},
}
@article{gelfand_sampling-based_1990,
    title = {Sampling-{Based} {Approaches} to {Calculating} {Marginal} {Densities}},
    volume = {85},
    issn = {0162-1459},
    url = {https://www.jstor.org/stable/2289776},
    doi = {10.2307/2289776},
    abstract = {Stochastic substitution, the Gibbs sampler, and the sampling-importance-resampling algorithm can be viewed as three alternative sampling- (or Monte Carlo-) based approaches to the calculation of numerical estimates of marginal probability distributions. The three approaches will be reviewed, compared, and contrasted in relation to various joint probability structures frequently encountered in applications. In particular, the relevance of the approaches to calculating Bayesian posterior densities for a variety of structured models will be discussed and illustrated.},
    number = {410},
    urldate = {2025-08-05},
    journal = {Journal of the American Statistical Association},
    author = {Gelfand, Alan E. and Smith, Adrian F. M.},
    year = {1990},
    note = {Publisher: [American Statistical Association, Taylor \& Francis, Ltd.]},
    pages = {398--409},
}
@article{skilling_nested_2006,
    title = {Nested sampling for general {Bayesian} computation},
    volume = {1},
    issn = {1936-0975, 1931-6690},
    url = {https://projecteuclid.org/journals/bayesian-analysis/volume-1/issue-4/Nested-sampling-for-general-Bayesian-computation/10.1214/06-BA127.full},
    doi = {10.1214/06-BA127},
    abstract = {Nested sampling estimates directly how the likelihood function relates to prior mass. The evidence (alternatively the marginal likelihood, marginal density of the data, or the prior predictive) is immediately obtained by summation. It is the prime result of the computation, and is accompanied by an estimate of numerical uncertainty. Samples from the posterior distribution are an optional by-product, obtainable for any temperature. The method relies on sampling within a hard constraint on likelihood value, as opposed to the softened likelihood of annealing methods. Progress depends only on the shape of the "nested" contours of likelihood, and not on the likelihood values. This invariance (over monotonic re-labelling) allows the method to deal with a class of phase-change problems which effectively defeat thermal annealing.},
    number = {4},
    urldate = {2025-08-05},
    journal = {Bayesian Analysis},
    author = {Skilling, John},
    month = dec,
    year = {2006},
    note = {Publisher: International Society for Bayesian Analysis},
    keywords = {Bayesian computation, Model selection, algorithm, annealing, evidence, marginal likelihood, nest, phase change},
    pages = {833--859},
}
@article{duane_hybrid_1987,
    title = {Hybrid {Monte} {Carlo}},
    volume = {195},
    issn = {0370-2693},
    url = {https://ui.adsabs.harvard.edu/abs/1987PhLB..195..216D/abstract},
    doi = {10.1016/0370-2693(87)91197-X},
    abstract = {We present a new method for the numerical simulation of lattice field theory. A hybrid (molecular dynamics/Langevin) algorithm is used to guide a Monte Carlo simulation. There are no discretization errors even for large step sizes. The method is especially efficient for systems such as quantum chromodynamics which contain fermionic degrees of freedom. Detailed results are presented for four-dimensional compact quantum electrodynamics including the dynamical effects of electrons.},
    language = {en},
    number = {2},
    urldate = {2025-08-05},
    journal = {Physics Letters B},
    author = {Duane, Simon and Kennedy, A. D. and Pendleton, Brian J. and Roweth, Duncan},
    month = sep,
    year = {1987},
    pages = {216--222},
}
@article{neal_mcmc_2011,
    title = {{MCMC} {Using} {Hamiltonian} {Dynamics}},
    url = {https://ui.adsabs.harvard.edu/abs/2011hmcm.book..113N/abstract},
    doi = {10.1201/b10905},
    abstract = {Hamiltonian dynamics can be used to produce distant proposals for the Metropolis algorithm, thereby avoiding the slow exploration of the state space that results from the diffusive behaviour of simple random-walk proposals. Though originating in physics, Hamiltonian dynamics can be applied to most problems with continuous state spaces by simply introducing fictitious "momentum" variables. A key to its usefulness is that Hamiltonian dynamics preserves volume, and its trajectories can thus be used to define complex mappings without the need to account for a hard-to-compute Jacobian factor - a property that can be exactly maintained even when the dynamics is approximated by discretizing time. In this review, I discuss theoretical and practical aspects of Hamiltonian Monte Carlo, and present some of its variations, including using windows of states for deciding on acceptance or rejection, computing trajectories using fast approximations, tempering during the course of a trajectory to handle isolated modes, and short-cut methods that prevent useless trajectories from taking much computation time.},
    language = {en},
    urldate = {2025-08-05},
    journal = {Handbook of Markov Chain Monte Carlo},
    author = {Neal, Radford},
    month = may,
    year = {2011},
    note = {ISBN: 9781420079418},
    pages = {113--162},
}
@article{jordan_introduction_1999,
    title = {An {Introduction} to {Variational} {Methods} for {Graphical} {Models}},
    volume = {37},
    issn = {1573-0565},
    url = {https://doi.org/10.1023/A:1007665907178},
    doi = {10.1023/A:1007665907178},
    abstract = {This paper presents a tutorial introduction to the use of variational methods for inference and learning in graphical models (Bayesian networks and Markov random fields). We present a number of examples of graphical models, including the QMR-DT database, the sigmoid belief network, the Boltzmann machine, and several variants of hidden Markov models, in which it is infeasible to run exact inference algorithms. We then introduce variational methods, which exploit laws of large numbers to transform the original graphical model into a simplified graphical model in which inference is efficient. Inference in the simpified model provides bounds on probabilities of interest in the original model. We describe a general framework for generating variational transformations based on convex duality. Finally we return to the examples and demonstrate how variational algorithms can be formulated in each case.},
    language = {en},
    number = {2},
    urldate = {2025-08-05},
    journal = {Machine Learning},
    author = {Jordan, Michael I. and Ghahramani, Zoubin and Jaakkola, Tommi S. and Saul, Lawrence K.},
    month = nov,
    year = {1999},
    keywords = {Bayesian Inference, Bayesian Network, Bayesian networks, Boltzmann machines, Network Models, Non-parametric Inference, Parametric Inference, Statistical Learning, approximate inference, belief networks, graphical models, hidden Markov models, mean field methods, neural networks, probabilistic inference, variational methods},
    pages = {183--233},
}
@article{gelman_markov_1996,
    title = {Markov chain {Monte} {Carlo} methods in biostatistics},
    volume = {5},
    issn = {0962-2802},
    doi = {10.1177/096228029600500402},
    abstract = {Appropriate models in biostatistics are often quite complicated. Such models are typically most easily fit using Bayesian methods, which can often be implemented using simulation techniques. Markov chain Monte Carlo (MCMC) methods are an important set of tools for such simulations. We give an overview and references of this rapidly emerging technology along with a relatively simple example. MCMC techniques can be viewed as extensions of iterative maximization techniques, but with random jumps rather than maximizations at each step. Special care is needed when implementing iterative maximization procedures rather than closed-form methods, and even more care is needed with iterative simulation procedures: it is substantially more difficult to monitor convergence to a distribution than to a point. The most reliable implementations of MCMC build upon results from simpler models fit using combinations of maximization algorithms and noniterative simulations, so that the user has a rough idea of the location and scale of the posterior distribution of the quantities of interest under the more complicated model. These concerns with implementation, however, should not deter the biostatistician from using MCMC methods, but rather help to ensure wise use of these powerful techniques.},
    language = {eng},
    number = {4},
    journal = {Statistical Methods in Medical Research},
    author = {Gelman, A. and Rubin, D. B.},
    month = dec,
    year = {1996},
    pmid = {9004377},
    keywords = {Algorithms, Computer Simulation, Data Interpretation, Statistical, Humans, Likelihood Functions, Markov Chains, Mathematical Computing, Models, Statistical, Monte Carlo Method, Multivariate Analysis, Reaction Time, Sampling Studies, Schizophrenia},
    pages = {339--355},
}
@book{gelman_bayesian_2013,
    title = {Bayesian {Data} {Analysis}, {Third} {Edition}},
    isbn = {978-1-4398-4095-5},
    abstract = {Now in its third edition, this classic book is widely considered the leading text on Bayesian methods, lauded for its accessible, practical approach to analyzing data and solving research problems. Bayesian Data Analysis, Third Edition continues to take an applied approach to analysis using up-to-date Bayesian methods. The authors—all leaders in the statistics community—introduce basic concepts from a data-analytic perspective before presenting advanced methods. Throughout the text, numerous worked examples drawn from real applications and research emphasize the use of Bayesian inference in practice. New to the Third Edition   Four new chapters on nonparametric modeling Coverage of weakly informative priors and boundary-avoiding priors Updated discussion of cross-validation and predictive information criteria Improved convergence monitoring and effective sample size calculations for iterative simulation Presentations of Hamiltonian Monte Carlo, variational Bayes, and expectation propagation New and revised software code   The book can be used in three different ways. For undergraduate students, it introduces Bayesian inference starting from first principles. For graduate students, the text presents effective current approaches to Bayesian modeling and computation in statistics and related fields. For researchers, it provides an assortment of Bayesian methods in applied statistics. Additional materials, including data sets used in the examples, solutions to selected exercises, and software instructions, are available on the book’s web page.},
    language = {en},
    publisher = {CRC Press},
    author = {Gelman, Andrew and Carlin, John B. and Stern, Hal S. and Dunson, David B. and Vehtari, Aki and Rubin, Donald B.},
    month = nov,
    year = {2013},
    note = {Google-Books-ID: ZXL6AQAAQBAJ},
    keywords = {Computers / Mathematical \& Statistical Software, Mathematics / Probability \& Statistics / General, Psychology / Research \& Methodology},
}
@book{vapnik_estimation_2006,
    title = {Estimation of {Dependences} {Based} on {Empirical} {Data}},
    isbn = {978-0-387-34239-9},
    abstract = {Twenty-?ve years have passed since the publication of the Russian version of the book Estimation of Dependencies Based on Empirical Data (EDBED for short). Twen- ?ve years is a long period of time. During these years many things have happened. Looking back, one can see how rapidly life and technology have changed, and how slow and dif?cult it is to change the theoretical foundation of the technology and its philosophy. I pursued two goals writing this Afterword: to update the technical results presented in EDBED (the easy goal) and to describe a general picture of how the new ideas developed over these years (a much more dif?cult goal). The picture which I would like to present is a very personal (and therefore very biased) account of the development of one particular branch of science, Empirical - ference Science. Such accounts usually are not included in the content of technical publications. I have followed this rule in all of my previous books. But this time I would like to violate it for the following reasons. First of all, for me EDBED is the important milestone in the development of empirical inference theory and I would like to explain why. S- ond, during these years, there were a lot of discussions between supporters of the new 1 paradigm (now it is called the VC theory ) and the old one (classical statistics).},
    language = {en},
    publisher = {Springer Science \& Business Media},
    author = {Vapnik, V.},
    month = sep,
    year = {2006},
    keywords = {Mathematics / Applied, Mathematics / General},
}
@book{mackay_information_2003,
    title = {Information {Theory}, {Inference} and {Learning} {Algorithms}},
    isbn = {978-0-521-64298-9},
    abstract = {Information theory and inference, often taught separately, are here united in one entertaining textbook. These topics lie at the heart of many exciting areas of contemporary science and engineering - communication, signal processing, data mining, machine learning, pattern recognition, computational neuroscience, bioinformatics, and cryptography. This textbook introduces theory in tandem with applications. Information theory is taught alongside practical communication systems, such as arithmetic coding for data compression and sparse-graph codes for error-correction. A toolbox of inference techniques, including message-passing algorithms, Monte Carlo methods, and variational approximations, are developed alongside applications of these tools to clustering, convolutional codes, independent component analysis, and neural networks. The final part of the book describes the state of the art in error-correcting codes, including low-density parity-check codes, turbo codes, and digital fountain codes -- the twenty-first century standards for satellite communications, disk drives, and data broadcast. Richly illustrated, filled with worked examples and over 400 exercises, some with detailed solutions, David MacKay's groundbreaking book is ideal for self-learning and for undergraduate or graduate courses. Interludes on crosswords, evolution, and sex provide entertainment along the way. In sum, this is a textbook on information, communication, and coding for a new generation of students, and an unparalleled entry point into these subjects for professionals in areas as diverse as computational biology, financial engineering, and machine learning.},
    language = {en},
    publisher = {Cambridge University Press},
    author = {MacKay, David J. C.},
    month = sep,
    year = {2003},
    note = {Google-Books-ID: AKuMj4PN\_EMC},
    keywords = {Computers / Artificial Intelligence / Computer Vision \& Pattern Recognition, Computers / Computer Science, Computers / Data Science / Data Modeling \& Design, Computers / Data Science / Neural Networks, Computers / Information Theory, Mathematics / Algebra / General, Philosophy / Logic, Science / Physics / General, Technology \& Engineering / Electronics / General},
}
@article{fan_approximate_2013,
    title = {Approximate {Bayesian} computation via regression density estimation},
    volume = {2},
    issn = {2049-1573},
    url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/sta4.15},
    doi = {10.1002/sta4.15},
    abstract = {Approximate Bayesian computation (ABC) methods, which are applicable when the likelihood is difficult or impossible to calculate, are an active topic of current research. Most current ABC algorithms directly approximate the posterior distribution, but an alternative, less common strategy is to approximate the likelihood function. This has several advantages. First, in some problems, it is easier to approximate the likelihood than to approximate the posterior. Second, an approximation to the likelihood allows reference analyses to be constructed based solely on the likelihood. Third, it is straightforward to perform sensitivity analyses for several different choices of prior once an approximation to the likelihood is constructed, which needs to be done only once. The contribution of the present paper is to consider regression density estimation techniques to approximate the likelihood in the ABC setting. Our likelihood approximations build on recently developed marginal adaptation density estimators by extending them for conditional density estimation. Our approach facilitates reference Bayesian inference, as well as frequentist inference. The method is demonstrated via a challenging problem of inference for stereological extremes, where we perform both frequentist and Bayesian inference. Copyright © 2013 John Wiley \& Sons Ltd},
    language = {en},
    number = {1},
    urldate = {2025-08-07},
    journal = {Statistical Science},
    author = {Fan, Yanan and Nott, David J. and Sisson, Scott A.},
    year = {2013},
    note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/sta4.15},
    keywords = {approximate Bayesian computation, copulas, likelihood-free inference, multivariate density estimation, regression density estimation},
    pages = {34--48},
}
@article{robert_lack_2011,
    title = {Lack of confidence in approximate {Bayesian} computation model choice},
    volume = {108},
    url = {https://www.pnas.org/doi/10.1073/pnas.1102900108},
    doi = {10.1073/pnas.1102900108},
    abstract = {Approximate Bayesian computation (ABC) have become an essential tool for the analysis of complex stochastic models. Grelaud et al. [(2009) Bayesian Anal 3:427–442] advocated the use of ABC for model choice in the specific case of Gibbs random fields, relying on an intermodel sufficiency property to show that the approximation was legitimate. We implemented ABC model choice in a wide range of phylogenetic models in the Do It Yourself-ABC (DIY-ABC) software [Cornuet et al. (2008) Bioinformatics 24:2713–2719]. We now present arguments as to why the theoretical arguments for ABC model choice are missing, because the algorithm involves an unknown loss of information induced by the use of insufficient summary statistics. The approximation error of the posterior probabilities of the models under comparison may thus be unrelated with the computational effort spent in running an ABC algorithm. We then conclude that additional empirical verifications of the performances of the ABC procedure as those available in DIY-ABC are necessary to conduct model choice.},
    number = {37},
    urldate = {2025-08-05},
    journal = {Proceedings of the National Academy of Sciences},
    author = {Robert, Christian P. and Cornuet, Jean-Marie and Marin, Jean-Michel and Pillai, Natesh S.},
    month = sep,
    year = {2011},
    note = {Publisher: Proceedings of the National Academy of Sciences},
    pages = {15112--15117},
}
@article{blum_comparative_2013,
    title = {A {Comparative} {Review} of {Dimension} {Reduction} {Methods} in {Approximate} {Bayesian} {Computation}},
    volume = {28},
    issn = {0883-4237},
    url = {https://www.jstor.org/stable/43288487},
    abstract = {Approximate Bayesian computation (ABC) methods make use of comparisons between simulated and observed summary statistics to overcome the problem of computationally intractable likelihood functions. As the practical implementation of ABC requires computations based on vectors of summary statistics, rather than full data sets, a central question is how to derive low-dimensional summary statistics from the observed data with minimal loss of information. In this article we provide a comprehensive review and comparison of the performance of the principal methods of dimension reduction proposed in the ABC literature. The methods are split into three nonmutually exclusive classes consisting of best subset selection methods, projection techniques and regularization. In addition, we introduce two new methods of dimension reduction. The first is a best subset selection method based on Akaike and Bayesian information criteria, and the second uses ridge regression as a regularization procedure. We illustrate the performance of these dimension reduction techniques through the analysis of three challenging models and data sets.},
    number = {2},
    urldate = {2025-08-08},
    journal = {Statistical Science},
    author = {Blum, M. G. B. and Nunes, M. A. and Prangle, D. and Sisson, S. A.},
    year = {2013},
    note = {Publisher: Institute of Mathematical Statistics},
    pages = {189--208},
}
@article{halmos_application_1949,
    title = {Application of the {Radon}-{Nikodym} {Theorem} to the {Theory} of {Sufficient} {Statistics}},
    volume = {20},
    issn = {0003-4851, 2168-8990},
    url = {https://projecteuclid.org/journals/annals-of-mathematical-statistics/volume-20/issue-2/Application-of-the-Radon-Nikodym-Theorem-to-the-Theory-of/10.1214/aoms/1177730032.full},
    doi = {10.1214/aoms/1177730032},
    abstract = {The body of this paper is written in terms of very general and abstract ideas which have been popular in pure mathematical work on the theory of probability for the last two or three decades. It seems to us that these ideas, so fruitful in pure mathematics, have something to contribute to mathematical statistics also, and this paper is an attempt to illustrate the sort of contribution we have in mind. The purpose of generality here is not to solve immediate practical problems, but rather to capture the logical essence of an important concept (sufficient statistic), and in particular to disentangle that concept from such ideas as Euclidean space, dimensionality, partial differentiation, and the distinction between continuous and discrete distributions, which seem to us extraneous. In accordance with these principles the center of the stage is occupied by a completely abstract sample space--that is a set \$X\$ of objects \$x\$, to be thought of as possible outcomes of an experimental program, distributed according to an unknown one of a certain set of probability measures. Perhaps the most familiar concrete example in statistics is the one in which \$X\$ is \$n\$ dimensional Cartesian space, the points of which represent \$n\$ independent observations of a normally distributed random variable with unknown parameters, and in which the probability measures considered are those induced by the various common normal distributions of the individual observations. A statistic is defined, as usual, to be a function \$T\$ of the outcome, whose values, however, are not necessarily real numbers but may themselves be abstract entities. Thus, in the concrete example, the entire set of \$n\$ observations, or, less trivially, the sequence of all sample moments about the origin are statistics with values in an \$n\$ dimensional and in an infinite dimensional space respectively. Another illuminating and very general example of a statistic may be obtained as follows. Suppose that the outcomes of two not necessarily statistically independent programs are thought of as one united outcome--then the outcome \$T\$ of the first program alone is a statistic relative to the united program. A technical measure theoretic result, known as the Radon-Nikodym theorem, is important in the study of statistics such as \$T\$. It is, for example, essential to the very definition of the basic concept of conditional probability of a subset \$E\$ of \$X\$ given a value \$y\$ of \$T\$. The statistic \$T\$ is called sufficient for the given set \${\textbackslash}mathcal\{M\}\$ of probability measures if (somewhat loosely speaking) the conditional probability of a subset \$E\$ of \$X\$ given a value \$y\$ of \$T\$ is the same for every probability measure in \${\textbackslash}mathcal\{M\}\$. It is, for instance, well known that the sample mean and variance together form a sufficient statistic for the measures described in the concrete example. The theory of sufficiency is in an especially satisfactory state for the case in which the set \${\textbackslash}mathcal\{M\}\$ of probability measures satisfies a certain condition described by the technical term dominated. A set \${\textbackslash}mathcal\{M\}\$ of probability measures is called dominated if each measure in the set may be expressed as the indefinite integral of a density function with respect to a fixed measure which is not itself necessarily in the set. It is easy to verify that both classical extremes, commonly referred to as the discrete and continuous cases, are dominated. One possible formulation of the principal result concerning sufficiency for dominated sets is a direct generalization to the abstract case of the well known Fisher-Neyman result: \$T\$ is sufficient if and only if the densities can be written as products of two factors, the first of which depends on the outcome through \$T\$ only and the second of which is independent of the unknown measure. Another way of phrasing this result is to say that \$T\$ is sufficient if and only if the likelihood ratio of every pair of measures in \${\textbackslash}mathcal\{M\}\$ depends on the outcome through \$T\$ only. The latter formulation makes sense even in the not necessarily dominated case but unfortunately it is not true in that case. The situation can be patched up somewhat by introducing a weaker notion called pairwise sufficiency. In ordinary statistical parlance one often speaks of a statistic sufficient for some of several parameters. The abstract results mentioned above can undoubtedly be extended to treat this concept.},
    number = {2},
    urldate = {2025-08-08},
    journal = {The Annals of Mathematical Statistics},
    author = {Halmos, Paul R. and Savage, L. J.},
    month = jun,
    year = {1949},
    note = {Publisher: Institute of Mathematical Statistics},
    pages = {225--241},
}
@article{fisher_mathematical_1922,
    title = {On the {Mathematical} {Foundations} of {Theoretical} {Statistics}},
    volume = {222},
    issn = {0264-3952},
    url = {https://www.jstor.org/stable/91208},
    urldate = {2025-08-08},
    journal = {Philosophical Transactions of the Royal Society of London. Series A, Containing Papers of a Mathematical or Physical Character},
    author = {Fisher, R. A.},
    year = {1922},
    note = {Publisher: Royal Society},
    pages = {309--368},
}
@article{neyman_use_1928,
    title = {On the {Use} and {Interpretation} of {Certain} {Test} {Criteria} for {Purposes} of {Statistical} {Inference}: {Part} {I}},
    volume = {20A},
    issn = {0006-3444},
    shorttitle = {On the {Use} and {Interpretation} of {Certain} {Test} {Criteria} for {Purposes} of {Statistical} {Inference}},
    url = {https://www.jstor.org/stable/2331945},
    doi = {10.2307/2331945},
    number = {1/2},
    urldate = {2025-08-08},
    journal = {Biometrika},
    author = {Neyman, J. and Pearson, E. S.},
    year = {1928},
    note = {Publisher: [Oxford University Press, Biometrika Trust]},
    pages = {175--240},
}
@book{casella_statistical_2002,
    title = {Statistical {Inference}},
    isbn = {978-0-495-39187-6},
    abstract = {This book builds theoretical statistics from the first principles of probability theory. Starting from the basics of probability, the authors develop the theory of statistical inference using techniques, definitions, and concepts that are statistical and are natural extensions and consequences of previous concepts. Intended for first-year graduate students, this book can be used for students majoring in statistics who have a solid mathematics background. It can also be used in a way that stresses the more practical uses of statistical theory, being more concerned with understanding basic statistical concepts and deriving reasonable statistical procedures for a variety of situations, and less concerned with formal optimality investigations.},
    language = {en},
    publisher = {Duxbury Thomson Learning},
    author = {Casella, George and Berger, Roger L.},
    year = {2002},
    note = {Google-Books-ID: ZpkPPwAACAAJ},
}
@article{brown_fundamentals_1986,
    title = {Fundamentals of {Statistical} {Exponential} {Families} with {Applications} in {Statistical} {Decision} {Theory}},
    volume = {9},
    issn = {0749-2170},
    url = {https://www.jstor.org/stable/4355554},
    urldate = {2025-08-08},
    journal = {Lecture Notes-Monograph Series},
    author = {Brown, Lawrence D.},
    year = {1986},
    note = {Publisher: Institute of Mathematical Statistics},
    pages = {i--279},
}
@article{lehmann_completeness_1950,
    title = {Completeness, {Similar} {Regions}, and {Unbiased} {Estimation}: {Part} {I}},
    volume = {10},
    issn = {0036-4452},
    shorttitle = {Completeness, {Similar} {Regions}, and {Unbiased} {Estimation}},
    url = {https://www.jstor.org/stable/25048038},
    number = {4},
    urldate = {2025-08-08},
    journal = {Sankh\=a: The Indian Journal of Statistics (1933-1960)},
    author = {Lehmann, E. L. and Scheff{\'e}, Henry},
    year = {1950},
    note = {Publisher: Springer},
    pages = {305--340},
}
@book{cover_elements_2006,
    title = {Elements of {Information} {Theory}},
    isbn = {978-0-471-24195-9},
    abstract = {The latest edition of this classic is updated with new problem sets and material The Second Edition of this fundamental textbook maintains the book's tradition of clear, thought-provoking instruction. Readers are provided once again with an instructive mix of mathematics, physics, statistics, and information theory. All the essential topics in information theory are covered in detail, including entropy, data compression, channel capacity, rate distortion, network information theory, and hypothesis testing. The authors provide readers with a solid understanding of the underlying theory and applications. Problem sets and a telegraphic summary at the end of each chapter further assist readers. The historical notes that follow each chapter recap the main points. The Second Edition features:  Chapters reorganized to improve teaching 200 new problems New material on source coding, portfolio theory, and feedback capacity Updated references  Now current and enhanced, the Second Edition of Elements of Information Theory remains the ideal textbook for upper-level undergraduate and graduate courses in electrical engineering, statistics, and telecommunications.},
    language = {en},
    publisher = {John Wiley \& Sons},
    author = {Cover, Thomas M. and Thomas, Joy A.},
    month = jul,
    year = {2006},
    note = {Google-Books-ID: j0DBDwAAQBAJ},
    keywords = {Computers / Computer Science, Computers / General, Computers / Information Technology},
}
@book{kullback_information_1959,
    title = {Information {Theory} and {Statistics}},
    abstract = {Definition of information -- Properties of information -- Inequalities of information theory -- Limiting properties -- Information statistics -- Multinomial populations -- Poisson populations -- Contingency tables -- Multivariate normal populations -- The linear hypothesis -- Multivariate analysis: other hypothesis -- Linear discriminant functions.},
    language = {en},
    publisher = {Wiley},
    author = {Kullback, Solomon},
    year = {1959},
    note = {Google-Books-ID: XeRQAAAAMAAJ},
}
@article{shannon_mathematical_1948,
    title = {A {Mathematical} {Theory} of {Communication}},
    volume = {27},
    copyright = {© 1948 The Bell System Technical Journal},
    issn = {1538-7305},
    url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/j.1538-7305.1948.tb01338.x},
    doi = {10.1002/j.1538-7305.1948.tb01338.x},
    language = {en},
    number = {3},
    urldate = {2025-08-08},
    journal = {Bell System Technical Journal},
    author = {Shannon, C. E.},
    year = {1948},
    note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/j.1538-7305.1948.tb01338.x},
    pages = {379--423},
}
@book{lehmann_theory_1998,
    edition = {2},
    series = {Springer {Texts} in {Statistics}},
    title = {Theory of {Point} {Estimation}},
    publisher = {Springer New York, NY},
    author = {Lehmann, E. L. and Casella, George},
    year = {1998},
}
@article{clarke_information-theoretic_1990,
    title = {Information-theoretic asymptotics of {Bayes} methods},
    volume = {36},
    issn = {1557-9654},
    url = {https://ieeexplore.ieee.org/document/54897},
    doi = {10.1109/18.54897},
    abstract = {In the absence of knowledge of the true density function, Bayesian models take the joint density function for a sequence of n random variables to be an average of densities with respect to a prior. The authors examine the relative entropy distance D/sub n/ between the true density and the Bayesian density and show that the asymptotic distance is (d/2)(log n)+c, where d is the dimension of the parameter vector. Therefore, the relative entropy rate D/sub n//n converges to zero at rate (log n)/n. The constant c, which the authors explicitly identify, depends only on the prior density function and the Fisher information matrix evaluated at the true parameter value. Consequences are given for density estimation, universal data compression, composite hypothesis testing, and stock-market portfolio selection.{\textless}{\textgreater}},
    number = {3},
    urldate = {2025-08-08},
    journal = {IEEE Transactions on Information Theory},
    author = {Clarke, B.S. and Barron, A.R.},
    month = may,
    year = {1990},
    keywords = {Bayesian methods, Data compression, Density functional theory, Entropy, Information theory, Portfolios, Random variables, Statistics, Testing},
    pages = {453--471},
}
@book{goodfellow_deep_2016,
    title = {Deep {Learning}},
    isbn = {978-0-262-03561-3},
    url = {http://www.deeplearningbook.org},
    abstract = {An introduction to a broad range of topics in deep learning, covering mathematical and conceptual background, deep learning techniques used in industry, and research perspectives.“Written by three experts in the field, Deep Learning is the only comprehensive book on the subject.”—Elon Musk, cochair of OpenAI; cofounder and CEO of Tesla and SpaceXDeep learning is a form of machine learning that enables computers to learn from experience and understand the world in terms of a hierarchy of concepts. Because the computer gathers knowledge from experience, there is no need for a human computer operator to formally specify all the knowledge that the computer needs. The hierarchy of concepts allows the computer to learn complicated concepts by building them out of simpler ones; a graph of these hierarchies would be many layers deep. This book introduces a broad range of topics in deep learning. The text offers mathematical and conceptual background, covering relevant concepts in linear algebra, probability theory and information theory, numerical computation, and machine learning. It describes deep learning techniques used by practitioners in industry, including deep feedforward networks, regularization, optimization algorithms, convolutional networks, sequence modeling, and practical methodology; and it surveys such applications as natural language processing, speech recognition, computer vision, online recommendation systems, bioinformatics, and videogames. Finally, the book offers research perspectives, covering such theoretical topics as linear factor models, autoencoders, representation learning, structured probabilistic models, Monte Carlo methods, the partition function, approximate inference, and deep generative models. Deep Learning can be used by undergraduate or graduate students planning careers in either industry or research, and by software engineers who want to begin using deep learning in their products or platforms. A website offers supplementary material for both readers and instructors.},
    language = {en},
    publisher = {MIT Press},
    author = {Goodfellow, Ian and Bengio, Yoshua and Courville, Aaron},
    month = nov,
    year = {2016},
    note = {Google-Books-ID: Np9SDQAAQBAJ},
    keywords = {Computers / Artificial Intelligence / General, Computers / Computer Science, Computers / Data Science / Machine Learning},
}
@book{nielsen_neural_2015,
    title = {Neural {Networks} and {Deep} {Learning}},
    abstract = {"Neural Networks and Deep Learning is a free online book. The book will teach you about: Neural networks, a beautiful biologically-inspired programming paradigm which enables a computer to learn from observational data Deep learning, a powerful set of techniques for learning in neural networks Neural networks and deep learning currently provide the best solutions to many problems in image recognition, speech recognition, and natural language processing. This book will teach you many of the core concepts behind neural networks and deep learning."--Site web du livre.},
    language = {en},
    publisher = {Determination Press},
    author = {Nielsen, Michael A.},
    year = {2015},
    note = {Google-Books-ID: STDBswEACAAJ},
}
@book{bishop_pattern_2006,
    title = {Pattern {Recognition} and {Machine} {Learning}},
    isbn = {978-0-387-31073-2},
    abstract = {This is the first textbook on pattern recognition to present the Bayesian viewpoint. The book presents approximate inference algorithms that permit fast approximate answers in situations where exact answers are not feasible. It uses graphical models to describe probability distributions when no other books apply graphical models to machine learning. No previous knowledge of pattern recognition or machine learning concepts is assumed. Familiarity with multivariate calculus and basic linear algebra is required, and some experience in the use of probabilities would be helpful though not essential as the book includes a self-contained introduction to basic probability theory.},
    language = {en},
    publisher = {Springer},
    author = {Bishop, Christopher M.},
    month = aug,
    year = {2006},
    note = {Google-Books-ID: kTNoQgAACAAJ},
    keywords = {Computers / Computer Graphics, Computers / Computer Vision \& Pattern Recognition, Computers / Intelligence (AI) \& Semantics, Mathematics / Probability \& Statistics / General},
}
@article{papamakarios_normalizing_2021,
    title = {Normalizing {Flows} for {Probabilistic} {Modeling} and {Inference}},
    volume = {22},
    issn = {1533-7928},
    url = {http://jmlr.org/papers/v22/19-1028.html},
    abstract = {Normalizing flows provide a general mechanism for defining expressive probability distributions, only requiring the specification of a (usually simple) base distribution and a series of bijective transformations. There has been much recent work on normalizing flows, ranging from improving their expressive power to expanding their application. We believe the field has now matured and is in need of a unified perspective. In this review, we attempt to provide such a perspective by describing flows through the lens of probabilistic modeling and inference. We place special emphasis on the fundamental principles of flow design, and discuss foundational topics such as expressive power and computational trade-offs. We also broaden the conceptual framing of flows by relating them to more general probability transformations. Lastly, we summarize the use of flows for tasks such as generative modeling, approximate inference, and supervised learning.},
    number = {57},
    urldate = {2025-08-12},
    journal = {Journal of Machine Learning Research},
    author = {Papamakarios, George and Nalisnick, Eric and Rezende, Danilo Jimenez and Mohamed, Shakir and Lakshminarayanan, Balaji},
    year = {2021},
    pages = {1--64},
}
@inproceedings{nix_estimating_1994,
    title = {Estimating the mean and variance of the target probability distribution},
    volume = {1},
    url = {https://ieeexplore.ieee.org/document/374138},
    doi = {10.1109/ICNN.1994.374138},
    abstract = {Introduces a method that estimates the mean and the variance of the probability distribution of the target as a function of the input, given an assumed target error-distribution model. Through the activation of an auxiliary output unit, this method provides a measure of the uncertainty of the usual network output for each input pattern. The authors derive the cost function and weight-update equations for the example of a Gaussian target error distribution, and demonstrate the feasibility of the network on a synthetic problem where the true input-dependent noise level is known.{\textless}{\textgreater}},
    urldate = {2025-08-16},
    booktitle = {Proceedings of 1994 {IEEE} {International} {Conference} on {Neural} {Networks} ({ICNN}'94)},
    author = {Nix, D.A. and Weigend, A.S.},
    month = jun,
    year = {1994},
    keywords = {Cognitive science, Computer errors, Computer science, Cost function, Equations, Error correction, Feedforward systems, Measurement uncertainty, Noise level, Probability distribution},
    pages = {55--60 vol.1},
}
@misc{kingma_adam_2017,
    title = {Adam: {A} {Method} for {Stochastic} {Optimization}},
    shorttitle = {Adam},
    url = {http://arxiv.org/abs/1412.6980},
    doi = {10.48550/arXiv.1412.6980},
    abstract = {We introduce Adam, an algorithm for first-order gradient-based optimization of stochastic objective functions, based on adaptive estimates of lower-order moments. The method is straightforward to implement, is computationally efficient, has little memory requirements, is invariant to diagonal rescaling of the gradients, and is well suited for problems that are large in terms of data and/or parameters. The method is also appropriate for non-stationary objectives and problems with very noisy and/or sparse gradients. The hyper-parameters have intuitive interpretations and typically require little tuning. Some connections to related algorithms, on which Adam was inspired, are discussed. We also analyze the theoretical convergence properties of the algorithm and provide a regret bound on the convergence rate that is comparable to the best known results under the online convex optimization framework. Empirical results demonstrate that Adam works well in practice and compares favorably to other stochastic optimization methods. Finally, we discuss AdaMax, a variant of Adam based on the infinity norm.},
    urldate = {2025-08-17},
    publisher = {arXiv},
    author = {Kingma, Diederik P. and Ba, Jimmy},
    month = jan,
    year = {2017},
    note = {arXiv:1412.6980 [cs]},
    keywords = {Computer Science - Machine Learning},
}
@misc{ioffe_batch_2015,
    title = {Batch {Normalization}: {Accelerating} {Deep} {Network} {Training} by {Reducing} {Internal} {Covariate} {Shift}},
    shorttitle = {Batch {Normalization}},
    url = {http://arxiv.org/abs/1502.03167},
    doi = {10.48550/arXiv.1502.03167},
    abstract = {Training Deep Neural Networks is complicated by the fact that the distribution of each layer's inputs changes during training, as the parameters of the previous layers change. This slows down the training by requiring lower learning rates and careful parameter initialization, and makes it notoriously hard to train models with saturating nonlinearities. We refer to this phenomenon as internal covariate shift, and address the problem by normalizing layer inputs. Our method draws its strength from making normalization a part of the model architecture and performing the normalization for each training mini-batch. Batch Normalization allows us to use much higher learning rates and be less careful about initialization. It also acts as a regularizer, in some cases eliminating the need for Dropout. Applied to a state-of-the-art image classification model, Batch Normalization achieves the same accuracy with 14 times fewer training steps, and beats the original model by a significant margin. Using an ensemble of batch-normalized networks, we improve upon the best published result on ImageNet classification: reaching 4.9\% top-5 validation error (and 4.8\% test error), exceeding the accuracy of human raters.},
    urldate = {2025-08-17},
    publisher = {arXiv},
    author = {Ioffe, Sergey and Szegedy, Christian},
    month = mar,
    year = {2015},
    note = {arXiv:1502.03167 [cs]},
    keywords = {Computer Science - Machine Learning},
}
@article{mehta_high-bias_2019,
    title = {A high-bias, low-variance introduction to {Machine} {Learning} for physicists},
    volume = {810},
    issn = {03701573},
    url = {http://arxiv.org/abs/1803.08823},
    doi = {10.1016/j.physrep.2019.03.001},
    abstract = {Machine Learning (ML) is one of the most exciting and dynamic areas of modern research and application. The purpose of this review is to provide an introduction to the core concepts and tools of machine learning in a manner easily understood and intuitive to physicists. The review begins by covering fundamental concepts in ML and modern statistics such as the bias-variance tradeoff, overfitting, regularization, generalization, and gradient descent before moving on to more advanced topics in both supervised and unsupervised learning. Topics covered in the review include ensemble models, deep learning and neural networks, clustering and data visualization, energy-based models (including MaxEnt models and Restricted Boltzmann Machines), and variational methods. Throughout, we emphasize the many natural connections between ML and statistical physics. A notable aspect of the review is the use of Python Jupyter notebooks to introduce modern ML/statistical packages to readers using physics-inspired datasets (the Ising Model and Monte-Carlo simulations of supersymmetric decays of proton-proton collisions). We conclude with an extended outlook discussing possible uses of machine learning for furthering our understanding of the physical world as well as open problems in ML where physicists may be able to contribute. (Notebooks are available at https://physics.bu.edu/{\textasciitilde}pankajm/MLnotebooks.html )},
    urldate = {2025-08-17},
    journal = {Physics Reports},
    author = {Mehta, Pankaj and Bukov, Marin and Wang, Ching-Hao and Day, Alexandre G. R. and Richardson, Clint and Fisher, Charles K. and Schwab, David J.},
    month = may,
    year = {2019},
    note = {arXiv:1803.08823 [physics]},
    keywords = {Computer Science - Machine Learning, Condensed Matter - Statistical Mechanics, Physics - Computational Physics, Statistics - Machine Learning},
    pages = {1--124},
}
@misc{garipov_loss_2018,
    title = {Loss {Surfaces}, {Mode} {Connectivity}, and {Fast} {Ensembling} of {DNNs}},
    url = {http://arxiv.org/abs/1802.10026},
    doi = {10.48550/arXiv.1802.10026},
    abstract = {The loss functions of deep neural networks are complex and their geometric properties are not well understood. We show that the optima of these complex loss functions are in fact connected by simple curves over which training and test accuracy are nearly constant. We introduce a training procedure to discover these high-accuracy pathways between modes. Inspired by this new geometric insight, we also propose a new ensembling method entitled Fast Geometric Ensembling (FGE). Using FGE we can train high-performing ensembles in the time required to train a single model. We achieve improved performance compared to the recent state-of-the-art Snapshot Ensembles, on CIFAR-10, CIFAR-100, and ImageNet.},
    urldate = {2025-08-17},
    publisher = {arXiv},
    author = {Garipov, Timur and Izmailov, Pavel and Podoprikhin, Dmitrii and Vetrov, Dmitry and Wilson, Andrew Gordon},
    month = oct,
    year = {2018},
    note = {arXiv:1802.10026 [stat]},
    keywords = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning, Statistics - Machine Learning},
}
@misc{gu_neural_2015,
    title = {Neural {Adaptive} {Sequential} {Monte} {Carlo}},
    url = {http://arxiv.org/abs/1506.03338},
    doi = {10.48550/arXiv.1506.03338},
    abstract = {Sequential Monte Carlo (SMC), or particle filtering, is a popular class of methods for sampling from an intractable target distribution using a sequence of simpler intermediate distributions. Like other importance sampling-based methods, performance is critically dependent on the proposal distribution: a bad proposal can lead to arbitrarily inaccurate estimates of the target distribution. This paper presents a new method for automatically adapting the proposal using an approximation of the Kullback-Leibler divergence between the true posterior and the proposal distribution. The method is very flexible, applicable to any parameterized proposal distribution and it supports online and batch variants. We use the new framework to adapt powerful proposal distributions with rich parameterizations based upon neural networks leading to Neural Adaptive Sequential Monte Carlo (NASMC). Experiments indicate that NASMC significantly improves inference in a non-linear state space model outperforming adaptive proposal methods including the Extended Kalman and Unscented Particle Filters. Experiments also indicate that improved inference translates into improved parameter learning when NASMC is used as a subroutine of Particle Marginal Metropolis Hastings. Finally we show that NASMC is able to train a latent variable recurrent neural network (LV-RNN) achieving results that compete with the state-of-the-art for polymorphic music modelling. NASMC can be seen as bridging the gap between adaptive SMC methods and the recent work in scalable, black-box variational inference.},
    urldate = {2024-11-18},
    publisher = {arXiv},
    author = {Gu, Shixiang and Ghahramani, Zoubin and Turner, Richard E.},
    month = nov,
    year = {2015},
    note = {arXiv:1506.03338},
    keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, cited, done},
}
@misc{paige_inference_2016,
    title = {Inference {Networks} for {Sequential} {Monte} {Carlo} in {Graphical} {Models}},
    url = {http://arxiv.org/abs/1602.06701},
    doi = {10.48550/arXiv.1602.06701},
    abstract = {We introduce a new approach for amortizing inference in directed graphical models by learning heuristic approximations to stochastic inverses, designed specifically for use as proposal distributions in sequential Monte Carlo methods. We describe a procedure for constructing and learning a structured neural network which represents an inverse factorization of the graphical model, resulting in a conditional density estimator that takes as input particular values of the observed random variables, and returns an approximation to the distribution of the latent variables. This recognition model can be learned offline, independent from any particular dataset, prior to performing inference. The output of these networks can be used as automatically-learned high-quality proposal distributions to accelerate sequential Monte Carlo across a diverse range of problem settings.},
    urldate = {2024-11-15},
    publisher = {arXiv},
    author = {Paige, Brooks and Wood, Frank},
    month = feb,
    year = {2016},
    note = {arXiv:1602.06701},
    keywords = {Statistics - Machine Learning, cited, done},
}
@article{Le2016InferenceCompilationUniversal,
    title = {Inference compilation and universal probabilistic programming},
    url = {http://arxiv.org/abs/1610.09900},
    author = {Le, Tuan Anh and Baydin, Atilim Gunes and Wood, Frank},
    month = oct,
    year = {2016},
    note = {arXiv: 1610.09900 [cs.AI]
tex.arxivid: 1610.09900},
    keywords = {cited, done},
}
@article{Papamakarios2016FastFreeInference,
    title = {Fast {\textless}span class="nocase"{\textgreater}ϵ{\textless}/span{\textgreater}-free inference of simulation models with bayesian conditional density estimation},
    url = {http://arxiv.org/abs/1605.06376},
    author = {Papamakarios, George and Murray, Iain},
    month = may,
    year = {2016},
    note = {arXiv: 1605.06376 [stat.ML]
tex.arxivid: 1605.06376},
    keywords = {cited, done},
}
@article{Ambrogioni2018ForwardAmortizedInference,
    title = {Forward amortized inference for likelihood-free variational marginalization},
    url = {http://arxiv.org/abs/1805.11542},
    author = {Ambrogioni, Luca and Güçlü, Umut and Berezutskaya, Julia and van den Borne, Eva W P and Güçlütürk, Yağmur and Hinne, Max and Maris, Eric and van Gerven, Marcel A J},
    month = may,
    year = {2018},
    note = {arXiv: 1805.11542 [stat.ML]
tex.arxivid: 1805.11542},
    keywords = {cited, done},
}
@article{Papamakarios2018SequentialNeuralLikelihood,
    title = {Sequential neural likelihood: {Fast} likelihood-free inference with autoregressive flows},
    url = {http://arxiv.org/abs/1805.07226},
    author = {Papamakarios, George and Sterratt, David C and Murray, Iain},
    month = may,
    year = {2018},
    note = {arXiv: 1805.07226 [stat.ML]
tex.arxivid: 1805.07226},
    keywords = {cited, done, read again},
}
@article{charnock_automatic_2018,
    title = {Automatic physical inference with information maximising neural networks},
    volume = {97},
    issn = {2470-0010, 2470-0029},
    url = {http://arxiv.org/abs/1802.03537},
    doi = {10.1103/PhysRevD.97.083004},
    abstract = {Compressing large data sets to a manageable number of summaries that are informative about the underlying parameters vastly simplifies both frequentist and Bayesian inference. When only simulations are available, these summaries are typically chosen heuristically, so they may inadvertently miss important information. We introduce a simulation-based machine learning technique that trains artificial neural networks to find non-linear functionals of data that maximise Fisher information: information maximising neural networks (IMNNs). In test cases where the posterior can be derived exactly, likelihood-free inference based on automatically derived IMNN summaries produces nearly exact posteriors, showing that these summaries are good approximations to sufficient statistics. In a series of numerical examples of increasing complexity and astrophysical relevance we show that IMNNs are robustly capable of automatically finding optimal, non-linear summaries of the data even in cases where linear compression fails: inferring the variance of Gaussian signal in the presence of noise; inferring cosmological parameters from mock simulations of the Lyman-\{{\textbackslash}alpha\} forest in quasar spectra; and inferring frequency-domain parameters from LISA-like detections of gravitational waveforms. In this final case, the IMNN summary outperforms linear data compression by avoiding the introduction of spurious likelihood maxima. We anticipate that the automatic physical inference method described in this paper will be essential to obtain both accurate and precise cosmological parameter estimates from complex and large astronomical data sets, including those from LSST and Euclid.},
    number = {8},
    urldate = {2022-06-05},
    journal = {Physical Review D},
    author = {Charnock, Tom and Lavaux, Guilhem and Wandelt, Benjamin D.},
    month = apr,
    year = {2018},
    note = {arXiv:1802.03537 [astro-ph]},
    keywords = {Astrophysics - Instrumentation and Methods for Astrophysics},
    pages = {083004},
}
@article{Alsing2018MassiveOptimalData,
    title = {Massive optimal data compression and density estimation for scalable, likelihood-free inference in cosmology},
    url = {http://arxiv.org/abs/1801.01497},
    author = {Alsing, Justin and Wandelt, Benjamin and Feeney, Stephen},
    year = {2018},
    note = {arXiv: 1801.01497 [astro-ph.CO]
tex.arxivid: 1801.01497},
}
@article{jeffrey_evidence_2024,
    title = {Evidence {Networks}: simple losses for fast, amortized, neural {Bayesian} model comparison},
    volume = {5},
    shorttitle = {Evidence {Networks}},
    doi = {10.1088/2632-2153/ad1a4d},
    number = {1},
    journal = {Mach. Learn. Sci. Tech.},
    author = {Jeffrey, Niall and Wandelt, Benjamin D.},
    year = {2024},
    note = {\_eprint: 2305.11241},
    keywords = {Bayesian model comparison, applications, deep learning, done, simulation-based inference},
    pages = {015008},
}
@article{rizvi_learning_2024,
    title = {Learning likelihood ratios with neural network classifiers},
    volume = {02},
    doi = {10.1007/JHEP02(2024)136},
    journal = {JHEP},
    author = {Rizvi, Shahzar and Pettee, Mariel and Nachman, Benjamin},
    year = {2024},
    note = {\_eprint: 2305.10500},
    keywords = {Jets and Jet Substructure, Parton Distributions, cited, done, neural network, parametrization, performance, statistical, statistical analysis},
    pages = {136},
}
@techreport{izbicki_high-dimensional_2014,
    title = {High-{Dimensional} {Density} {Ratio} {Estimation} with {Extensions} to {Approximate} {Likelihood} {Computation}},
    url = {http://arxiv.org/abs/1404.7063},
    abstract = {The ratio between two probability density functions is an important component of various tasks, including selection bias correction, novelty detection and classification. Recently, several estimators of this ratio have been proposed. Most of these methods fail if the sample space is high-dimensional, and hence require a dimension reduction step, the result of which can be a significant loss of information. Here we propose a simple-to-implement, fully nonparametric density ratio estimator that expands the ratio in terms of the eigenfunctions of a kernel-based operator; these functions reflect the underlying geometry of the data (e.g., submanifold structure), often leading to better estimates without an explicit dimension reduction step. We show how our general framework can be extended to address another important problem, the estimation of a likelihood function in situations where that function cannot be well-approximated by an analytical form. One is often faced with this situation when performing statistical inference with data from the sciences, due the complexity of the data and of the processes that generated those data. We emphasize applications where using existing likelihood-free methods of inference would be challenging due to the high dimensionality of the sample space, but where our spectral series method yields a reasonable estimate of the likelihood function. We provide theoretical guarantees and illustrate the effectiveness of our proposed method with numerical experiments.},
    number = {arXiv:1404.7063},
    urldate = {2022-06-01},
    institution = {arXiv},
    author = {Izbicki, Rafael and Lee, Ann B. and Schafer, Chad M.},
    month = apr,
    year = {2014},
    doi = {10.48550/arXiv.1404.7063},
    note = {arXiv:1404.7063 [stat]
type: article},
    keywords = {62G, 62M15, Statistics - Methodology, cited, done},
}
@misc{dinev_dynamic_2018,
    title = {Dynamic {Likelihood}-free {Inference} via {Ratio} {Estimation} ({DIRE})},
    url = {http://arxiv.org/abs/1810.09899},
    doi = {10.48550/arXiv.1810.09899},
    abstract = {Parametric statistical models that are implicitly defined in terms of a stochastic data generating process are used in a wide range of scientific disciplines because they enable accurate modeling. However, learning the parameters from observed data is generally very difficult because their likelihood function is typically intractable. Likelihood-free Bayesian inference methods have been proposed which include the frameworks of approximate Bayesian computation (ABC), synthetic likelihood, and its recent generalization that performs likelihood-free inference by ratio estimation (LFIRE). A major difficulty in all these methods is choosing summary statistics that reduce the dimensionality of the data to facilitate inference. While several methods for choosing summary statistics have been proposed for ABC, the literature for synthetic likelihood and LFIRE is very thin to date. We here address this gap in the literature, focusing on the important special case of time-series models. We show that convolutional neural networks trained to predict the input parameters from the data provide suitable summary statistics for LFIRE. On a wide range of time-series models, a single neural network architecture produced equally or more accurate posteriors than alternative methods.},
    urldate = {2024-10-18},
    publisher = {arXiv},
    author = {Dinev, Traiko and Gutmann, Michael U.},
    month = oct,
    year = {2018},
    note = {arXiv:1810.09899},
    keywords = {Computer Science - Machine Learning, Statistics - Computation, Statistics - Machine Learning, Statistics - Methodology, cited, done},
}
@misc{thomas_likelihood-free_2020,
    title = {Likelihood-free inference by ratio estimation},
    url = {http://arxiv.org/abs/1611.10242},
    doi = {10.48550/arXiv.1611.10242},
    abstract = {We consider the problem of parametric statistical inference when likelihood computations are prohibitively expensive but sampling from the model is possible. Several so-called likelihood-free methods have been developed to perform inference in the absence of a likelihood function. The popular synthetic likelihood approach infers the parameters by modelling summary statistics of the data by a Gaussian probability distribution. In another popular approach called approximate Bayesian computation, the inference is performed by identifying parameter values for which the summary statistics of the simulated data are close to those of the observed data. Synthetic likelihood is easier to use as no measure of `closeness' is required but the Gaussianity assumption is often limiting. Moreover, both approaches require judiciously chosen summary statistics. We here present an alternative inference approach that is as easy to use as synthetic likelihood but not as restricted in its assumptions, and that, in a natural way, enables automatic selection of relevant summary statistic from a large set of candidates. The basic idea is to frame the problem of estimating the posterior as a problem of estimating the ratio between the data generating distribution and the marginal distribution. This problem can be solved by logistic regression, and including regularising penalty terms enables automatic selection of the summary statistics relevant to the inference task. We illustrate the general theory on canonical examples and employ it to perform inference for challenging stochastic nonlinear dynamical systems and high-dimensional summary statistics.},
    urldate = {2024-11-18},
    publisher = {arXiv},
    author = {Thomas, Owen and Dutta, Ritabrata and Corander, Jukka and Kaski, Samuel and Gutmann, Michael U.},
    month = sep,
    year = {2020},
    note = {arXiv:1611.10242},
    keywords = {Statistics - Computation, Statistics - Machine Learning, Statistics - Methodology, cited, done},
}
@article{Cranmer2015ApproximatingLikelihoodRatios,
    title = {Approximating likelihood ratios with calibrated discriminative classifiers},
    url = {http://arxiv.org/abs/1506.02169},
    author = {Cranmer, Kyle and Pavez, Juan and Louppe, Gilles},
    year = {2015},
    note = {arXiv: 1506.02169 [stat.AP]
tex.arxivid: 1506.02169},
    keywords = {cited, done},
}
@article{Hermans2019LikelihoodfreeMCMCAmortized,
    title = {Likelihood-free {MCMC} with amortized approximate ratio estimators},
    url = {http://arxiv.org/abs/1903.04057},
    author = {Hermans, Joeri and Begy, Volodimir and Louppe, Gilles},
    month = mar,
    year = {2019},
    note = {arXiv: 1903.04057 [stat.ML]
tex.arxivid: 1903.04057},
    keywords = {cited, done},
}
@techreport{rhodes_telescoping_2020,
    title = {Telescoping {Density}-{Ratio} {Estimation}},
    url = {http://arxiv.org/abs/2006.12204},
    abstract = {Density-ratio estimation via classification is a cornerstone of unsupervised learning. It has provided the foundation for state-of-the-art methods in representation learning and generative modelling, with the number of use-cases continuing to proliferate. However, it suffers from a critical limitation: it fails to accurately estimate ratios p/q for which the two densities differ significantly. Empirically, we find this occurs whenever the KL divergence between p and q exceeds tens of nats. To resolve this limitation, we introduce a new framework, telescoping density-ratio estimation (TRE), that enables the estimation of ratios between highly dissimilar densities in high-dimensional spaces. Our experiments demonstrate that TRE can yield substantial improvements over existing single-ratio methods for mutual information estimation, representation learning and energy-based modelling.},
    number = {arXiv:2006.12204},
    urldate = {2022-06-06},
    institution = {arXiv},
    author = {Rhodes, Benjamin and Xu, Kai and Gutmann, Michael U.},
    month = nov,
    year = {2020},
    doi = {10.48550/arXiv.2006.12204},
    note = {arXiv:2006.12204 [cs, stat]
type: article},
    keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, cited, done},
}
@misc{lipman_flow_2023,
    title = {Flow {Matching} for {Generative} {Modeling}},
    url = {http://arxiv.org/abs/2210.02747},
    doi = {10.48550/arXiv.2210.02747},
    abstract = {We introduce a new paradigm for generative modeling built on Continuous Normalizing Flows (CNFs), allowing us to train CNFs at unprecedented scale. Specifically, we present the notion of Flow Matching (FM), a simulation-free approach for training CNFs based on regressing vector fields of fixed conditional probability paths. Flow Matching is compatible with a general family of Gaussian probability paths for transforming between noise and data samples -- which subsumes existing diffusion paths as specific instances. Interestingly, we find that employing FM with diffusion paths results in a more robust and stable alternative for training diffusion models. Furthermore, Flow Matching opens the door to training CNFs with other, non-diffusion probability paths. An instance of particular interest is using Optimal Transport (OT) displacement interpolation to define the conditional probability paths. These paths are more efficient than diffusion paths, provide faster training and sampling, and result in better generalization. Training CNFs using Flow Matching on ImageNet leads to consistently better performance than alternative diffusion-based methods in terms of both likelihood and sample quality, and allows fast and reliable sample generation using off-the-shelf numerical ODE solvers.},
    urldate = {2025-08-17},
    publisher = {arXiv},
    author = {Lipman, Yaron and Chen, Ricky T. Q. and Ben-Hamu, Heli and Nickel, Maximilian and Le, Matt},
    month = feb,
    year = {2023},
    note = {arXiv:2210.02747 [cs]},
    keywords = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning, Statistics - Machine Learning},
}
@inproceedings{wildberger_flow_2023,
    title = {Flow {Matching} for {Scalable} {Simulation}-{Based} {Inference}},
    url = {https://openreview.net/forum?id=LdGjxxjfh8#all},
    abstract = {Neural posterior estimation methods based on discrete normalizing flows have become established tools for simulation-based inference (SBI), but scaling them to high-dimensional problems can be challenging. Building on recent advances in generative modeling, we here present flow matching posterior estimation (FMPE), a technique for SBI using continuous normalizing flows. Like diffusion models, and in contrast to discrete flows, flow matching allows for unconstrained architectures, providing enhanced flexibility for complex data modalities. Flow matching, therefore, enables exact density evaluation, fast training, and seamless scalability to large architectures---making it ideal for SBI. We show that FMPE achieves competitive performance on an established SBI benchmark, and then demonstrate its improved scalability on a challenging scientific problem: for gravitational-wave inference, FMPE outperforms methods based on comparable discrete flows, reducing training time by 30{\textbackslash}\% with substantially improved accuracy. Our work underscores the potential of FMPE to enhance performance in challenging inference scenarios, thereby paving the way for more advanced applications to scientific problems.},
    language = {en},
    urldate = {2024-10-17},
    author = {Wildberger, Jonas Bernhard and Dax, Maximilian and Buchholz, Simon and Green, Stephen R. and Macke, Jakob H. and Schölkopf, Bernhard},
    month = jul,
    year = {2023},
}
@article{white_maximum_1982,
    title = {Maximum {Likelihood} {Estimation} of {Misspecified} {Models}},
    volume = {50},
    issn = {0012-9682},
    url = {https://www.jstor.org/stable/1912526},
    doi = {10.2307/1912526},
    abstract = {This paper examines the consequences and detection of model misspecification when using maximum likelihood techniques for estimation and inference. The quasi-maximum likelihood estimator (OMLE) converges to a well defined limit, and may or may not be consistent for particular parameters of interest. Standard tests (Wald, Lagrange Multiplier, or Likelihood Ratio) are invalid in the presence of misspecification, but more general statistics are given which allow inferences to be drawn robustly. The properties of the QMLE and the information matrix are exploited to yield several useful tests for model misspecification.},
    number = {1},
    urldate = {2024-11-08},
    journal = {Econometrica},
    author = {White, Halbert},
    year = {1982},
    note = {Publisher: [Wiley, Econometric Society]},
    keywords = {cited, done},
    pages = {1--25},
}
@article{box_science_1976,
    title = {Science and {Statistics}},
    volume = {71},
    issn = {0162-1459},
    url = {https://www.tandfonline.com/doi/abs/10.1080/01621459.1976.10480949},
    doi = {10.1080/01621459.1976.10480949},
    abstract = {Aspects of scientific method are discussed: In particular, its representation as a motivated iteration in which, in succession, practice confronts theory, and theory, practice. Rapid progress requires sufficient flexibility to profit from such confrontations, and the ability to devise parsimonious but effective models, to worry selectively about model inadequacies and to employ mathematics skillfully but appropriately. The development of statistical methods at Rothamsted Experimental Station by Sir Ronald Fisher is used to illustrate these themes.},
    number = {356},
    urldate = {2025-08-19},
    journal = {Journal of the American Statistical Association},
    author = {Box, George E. P.},
    month = dec,
    year = {1976},
    note = {Publisher: ASA Website
\_eprint: https://www.tandfonline.com/doi/pdf/10.1080/01621459.1976.10480949},
    pages = {791--799},
}
@article{hausman_specification_1978,
    title = {Specification {Tests} in {Econometrics}},
    volume = {46},
    issn = {0012-9682},
    url = {https://www.jstor.org/stable/1913827},
    doi = {10.2307/1913827},
    abstract = {Using the result that under the null hypothesis of no misspecification an asymptotically efficient estimator must have zero asymptotic covariance with its difference from a consistent but asymptotically inefficient estimator, specification tests are devised for a number of model specifications in econometrics. Local power is calculated for small departures from the null hypothesis. An instrumental variable test as well as tests for a time series cross section model and the simultaneous equation model are presented. An empirical model provides evidence that unobserved individual factors are present which are not orthogonal to the included right-hand-side variable in a common econometric specification of an individual wage equation.},
    number = {6},
    urldate = {2025-08-19},
    journal = {Econometrica},
    author = {Hausman, J. A.},
    year = {1978},
    note = {Publisher: [Wiley, Econometric Society]},
    pages = {1251--1271},
}
@article{zhou_domain_2022,
    title = {Domain {Generalization}: {A} {Survey}},
    issn = {0162-8828, 2160-9292, 1939-3539},
    shorttitle = {Domain {Generalization}},
    url = {http://arxiv.org/abs/2103.02503},
    doi = {10.1109/TPAMI.2022.3195549},
    abstract = {Generalization to out-of-distribution (OOD) data is a capability natural to humans yet challenging for machines to reproduce. This is because most learning algorithms strongly rely on the i.i.d.{\textasciitilde}assumption on source/target data, which is often violated in practice due to domain shift. Domain generalization (DG) aims to achieve OOD generalization by using only source data for model learning. Over the last ten years, research in DG has made great progress, leading to a broad spectrum of methodologies, e.g., those based on domain alignment, meta-learning, data augmentation, or ensemble learning, to name a few; DG has also been studied in various application areas including computer vision, speech recognition, natural language processing, medical imaging, and reinforcement learning. In this paper, for the first time a comprehensive literature review in DG is provided to summarize the developments over the past decade. Specifically, we first cover the background by formally defining DG and relating it to other relevant fields like domain adaptation and transfer learning. Then, we conduct a thorough review into existing methods and theories. Finally, we conclude this survey with insights and discussions on future research directions.},
    urldate = {2025-08-19},
    journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
    author = {Zhou, Kaiyang and Liu, Ziwei and Qiao, Yu and Xiang, Tao and Loy, Chen Change},
    year = {2022},
    note = {arXiv:2103.02503 [cs]},
    keywords = {Computer Science - Artificial Intelligence, Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning},
    pages = {1--20},
}
@article{gelman_inference_1992,
    title = {Inference from {Iterative} {Simulation} {Using} {Multiple} {Sequences}},
    volume = {7},
    issn = {0883-4237, 2168-8745},
    url = {https://projecteuclid.org/journals/statistical-science/volume-7/issue-4/Inference-from-Iterative-Simulation-Using-Multiple-Sequences/10.1214/ss/1177011136.full},
    doi = {10.1214/ss/1177011136},
    abstract = {The Gibbs sampler, the algorithm of Metropolis and similar iterative simulation methods are potentially very helpful for summarizing multivariate distributions. Used naively, however, iterative simulation can give misleading answers. Our methods are simple and generally applicable to the output of any iterative simulation; they are designed for researchers primarily interested in the science underlying the data and models they are analyzing, rather than for researchers interested in the probability theory underlying the iterative simulations themselves. Our recommended strategy is to use several independent sequences, with starting points sampled from an overdispersed distribution. At each step of the iterative simulation, we obtain, for each univariate estimand of interest, a distributional estimate and an estimate of how much sharper the distributional estimate might become if the simulations were continued indefinitely. Because our focus is on applied inference for Bayesian posterior distributions in real problems, which often tend toward normality after transformations and marginalization, we derive our results as normal-theory approximations to exact Bayesian inference, conditional on the observed simulations. The methods are illustrated on a random-effects mixture model applied to experimental measurements of reaction times of normal and schizophrenic patients.},
    number = {4},
    urldate = {2024-11-08},
    journal = {Statistical Science},
    author = {Gelman, Andrew and Rubin, Donald B.},
    month = nov,
    year = {1992},
    note = {Publisher: Institute of Mathematical Statistics},
    keywords = {Bayesian inference, Convergence of stochastic processes, ECM, EM, Gibbs sampler, Metropolis algorithm, SIR, cited, done, importance sampling, multiple imputation, random-effects model},
    pages = {457--472},
}
@article{kiureghian_aleatory_2009,
    series = {Risk {Acceptance} and {Risk} {Communication}},
    title = {Aleatory or epistemic? {Does} it matter?},
    volume = {31},
    issn = {0167-4730},
    shorttitle = {Aleatory or epistemic?},
    url = {https://www.sciencedirect.com/science/article/pii/S0167473008000556},
    doi = {10.1016/j.strusafe.2008.06.020},
    abstract = {The sources and characters of uncertainties in engineering modeling for risk and reliability analyses are discussed. While many sources of uncertainty may exist, they are generally categorized as either aleatory or epistemic. Uncertainties are characterized as epistemic, if the modeler sees a possibility to reduce them by gathering more data or by refining models. Uncertainties are categorized as aleatory if the modeler does not foresee the possibility of reducing them. From a pragmatic standpoint, it is useful to thus categorize the uncertainties within a model, since it then becomes clear as to which uncertainties have the potential of being reduced. More importantly, epistemic uncertainties may introduce dependence among random events, which may not be properly noted if the character of uncertainties is not correctly modeled. Influences of the two types of uncertainties in reliability assessment, codified design, performance-based engineering and risk-based decision-making are discussed. Two simple examples demonstrate the influence of statistical dependence arising from epistemic uncertainties on systems and time-variant reliability problems.},
    number = {2},
    urldate = {2025-08-19},
    journal = {Structural Safety},
    author = {Kiureghian, Armen Der and Ditlevsen, Ove},
    month = mar,
    year = {2009},
    keywords = {Aleatory, Epistemic, Ergodicity, Parameter uncertainty, Predictive models, Probability distribution choice, Statistical dependence, Systems, Time-variant reliability, Uncertainty},
    pages = {105--112},
}
@misc{kendall_what_2017,
    title = {What {Uncertainties} {Do} {We} {Need} in {Bayesian} {Deep} {Learning} for {Computer} {Vision}?},
    url = {http://arxiv.org/abs/1703.04977},
    doi = {10.48550/arXiv.1703.04977},
    abstract = {There are two major types of uncertainty one can model. Aleatoric uncertainty captures noise inherent in the observations. On the other hand, epistemic uncertainty accounts for uncertainty in the model -- uncertainty which can be explained away given enough data. Traditionally it has been difficult to model epistemic uncertainty in computer vision, but with new Bayesian deep learning tools this is now possible. We study the benefits of modeling epistemic vs. aleatoric uncertainty in Bayesian deep learning models for vision tasks. For this we present a Bayesian deep learning framework combining input-dependent aleatoric uncertainty together with epistemic uncertainty. We study models under the framework with per-pixel semantic segmentation and depth regression tasks. Further, our explicit uncertainty formulation leads to new loss functions for these tasks, which can be interpreted as learned attenuation. This makes the loss more robust to noisy data, also giving new state-of-the-art results on segmentation and depth regression benchmarks.},
    urldate = {2025-08-19},
    publisher = {arXiv},
    author = {Kendall, Alex and Gal, Yarin},
    month = oct,
    year = {2017},
    note = {arXiv:1703.04977 [cs]},
    keywords = {Computer Science - Computer Vision and Pattern Recognition},
}
@article{liese_divergences_2006,
    title = {On {Divergences} and {Informations} in {Statistics} and {Information} {Theory}},
    volume = {52},
    issn = {1557-9654},
    url = {https://ieeexplore.ieee.org/document/1705001},
    doi = {10.1109/TIT.2006.881731},
    abstract = {The paper deals with thef-divergences of CsiszÁr generalizing the discrimination information of Kullback, the total variation distance, the Hellinger divergence, and the Pearson divergence. All basic properties off-divergences including relations to the decision errors are proved in a new manner replacing the classical Jensen inequality by a new generalized Taylor expansion of convex functions. Some new properties are proved too, e.g., relations to the statistical sufficiency and deficiency. The generalized Taylor expansion also shows very easily that allf-divergences are average statistical informations (differences between prior and posterior Bayes errors) mutually differing only in the weights imposed on various prior distributions. The statistical information introduced by De Groot and the classical information of Shannon are shown to be extremal cases corresponding toalpha =0andalpha =1in the class of the so-called Arimotoalpha -informations introduced in this paper for0≪ alpha ≪ 1by means of the Arimotoalpha -entropies. Some new examples off-divergences are introduced as well, namely, the Shannon divergences and the Arimotoalpha -divergences leading foralpha uparrow 1to the Shannon divergences. Square roots of all these divergences are shown to be metrics satisfying the triangle inequality. The last section introduces statistical tests and estimators based on the minimalf-divergence with the empirical distribution achieved in the families of hypothetic distributions. For the Kullback divergence this leads to the classical likelihood ratio test and estimator.},
    number = {10},
    urldate = {2025-08-20},
    journal = {IEEE Transactions on Information Theory},
    author = {Liese, F. and Vajda, I.},
    month = oct,
    year = {2006},
    keywords = {Arimoto divergence, Arimoto entropy, Arimoto information, Automation, Electronic mail, Entropy, Information theory, Mathematics, Probability, Random variables, Shannon divergence, Shannon information, Statistics, Taylor series, Testing, deficiency, discrimination information, minimum, statistical information, sufficiency},
    pages = {4394--4412},
}
@book{pardo_statistical_2018,
    address = {New York},
    title = {Statistical {Inference} {Based} on {Divergence} {Measures}},
    isbn = {978-0-429-14852-1},
    abstract = {The idea of using functionals of Information Theory, such as entropies or divergences, in statistical inference is not new. However, in spite of the fact that divergence statistics have become a very good alternative to the classical likelihood ratio test and the Pearson-type statistic in discrete models, many statisticians remain unaware of this p},
    publisher = {Chapman and Hall/CRC},
    author = {Pardo, Leandro},
    month = nov,
    year = {2018},
    doi = {10.1201/9781420034813},
}
@article{renyi_measures_1960,
    title = {On {Measures} of {Entropy} and {Information}},
    url = {https://digicoll.lib.berkeley.edu/record/112906},
    urldate = {2025-08-20},
    journal = {Proceedings of the Fourth Berkeley Symposium on Mathematical Statistics and Probability (June 20-July 30 1960)},
    author = {Rényi, Alfréd},
    year = {1960},
    note = {Num Pages: 547},
    keywords = {Shannon entropy},
}
@article{sason_divergence_2022,
    title = {Divergence {Measures}: {Mathematical} {Foundations} and {Applications} in {Information}-{Theoretic} and {Statistical} {Problems}},
    volume = {24},
    copyright = {http://creativecommons.org/licenses/by/3.0/},
    issn = {1099-4300},
    shorttitle = {Divergence {Measures}},
    url = {https://www.mdpi.com/1099-4300/24/5/712},
    doi = {10.3390/e24050712},
    abstract = {Data science, information theory, probability theory, statistical learning, statistical signal processing, and other related disciplines greatly benefit from non-negative measures of dissimilarity between pairs of probability measures [...]},
    language = {en},
    number = {5},
    urldate = {2025-08-20},
    journal = {Entropy},
    author = {Sason, Igal},
    month = may,
    year = {2022},
    note = {Publisher: Multidisciplinary Digital Publishing Institute},
    keywords = {n/a},
    pages = {712},
}
@misc{yu_training_2020,
    title = {Training {Deep} {Energy}-{Based} {Models} with f-{Divergence} {Minimization}},
    url = {http://arxiv.org/abs/2003.03463},
    doi = {10.48550/arXiv.2003.03463},
    abstract = {Deep energy-based models (EBMs) are very flexible in distribution parametrization but computationally challenging because of the intractable partition function. They are typically trained via maximum likelihood, using contrastive divergence to approximate the gradient of the KL divergence between data and model distribution. While KL divergence has many desirable properties, other f-divergences have shown advantages in training implicit density generative models such as generative adversarial networks. In this paper, we propose a general variational framework termed f-EBM to train EBMs using any desired f-divergence. We introduce a corresponding optimization algorithm and prove its local convergence property with non-linear dynamical systems theory. Experimental results demonstrate the superiority of f-EBM over contrastive divergence, as well as the benefits of training EBMs using f-divergences other than KL.},
    urldate = {2025-08-20},
    publisher = {arXiv},
    author = {Yu, Lantao and Song, Yang and Song, Jiaming and Ermon, Stefano},
    month = jul,
    year = {2020},
    note = {arXiv:2003.03463 [cs]},
    keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
}
@misc{ke_imitation_2020,
    title = {Imitation {Learning} as \$f\$-{Divergence} {Minimization}},
    url = {http://arxiv.org/abs/1905.12888},
    doi = {10.48550/arXiv.1905.12888},
    abstract = {We address the problem of imitation learning with multi-modal demonstrations. Instead of attempting to learn all modes, we argue that in many tasks it is sufficient to imitate any one of them. We show that the state-of-the-art methods such as GAIL and behavior cloning, due to their choice of loss function, often incorrectly interpolate between such modes. Our key insight is to minimize the right divergence between the learner and the expert state-action distributions, namely the reverse KL divergence or I-projection. We propose a general imitation learning framework for estimating and minimizing any f-Divergence. By plugging in different divergences, we are able to recover existing algorithms such as Behavior Cloning (Kullback-Leibler), GAIL (Jensen Shannon) and Dagger (Total Variation). Empirical results show that our approximate I-projection technique is able to imitate multi-modal behaviors more reliably than GAIL and behavior cloning.},
    urldate = {2025-08-20},
    publisher = {arXiv},
    author = {Ke, Liyiming and Choudhury, Sanjiban and Barnes, Matt and Sun, Wen and Lee, Gilwoo and Srinivasa, Siddhartha},
    month = may,
    year = {2020},
    note = {arXiv:1905.12888 [cs]},
    keywords = {Computer Science - Information Theory, Computer Science - Machine Learning, Computer Science - Robotics, Mathematics - Information Theory, Statistics - Machine Learning},
}
@techreport{cannon_investigating_2022,
    title = {Investigating the {Impact} of {Model} {Misspecification} in {Neural} {Simulation}-based {Inference}},
    url = {http://arxiv.org/abs/2209.01845},
    abstract = {Aided by advances in neural density estimation, considerable progress has been made in recent years towards a suite of simulation-based inference (SBI) methods capable of performing flexible, black-box, approximate Bayesian inference for stochastic simulation models. While it has been demonstrated that neural SBI methods can provide accurate posterior approximations, the simulation studies establishing these results have considered only well-specified problems -- that is, where the model and the data generating process coincide exactly. However, the behaviour of such algorithms in the case of model misspecification has received little attention. In this work, we provide the first comprehensive study of the behaviour of neural SBI algorithms in the presence of various forms of model misspecification. We find that misspecification can have a profoundly deleterious effect on performance. Some mitigation strategies are explored, but no approach tested prevents failure in all cases. We conclude that new approaches are required to address model misspecification if neural SBI algorithms are to be relied upon to derive accurate scientific conclusions.},
    number = {arXiv:2209.01845},
    urldate = {2022-09-11},
    institution = {arXiv},
    author = {Cannon, Patrick and Ward, Daniel and Schmon, Sebastian M.},
    month = sep,
    year = {2022},
    doi = {10.48550/arXiv.2209.01845},
    note = {arXiv:2209.01845 [cs, stat]
type: article},
    keywords = {Computer Science - Machine Learning, Statistics - Computation, Statistics - Machine Learning, cited, done},
}
@inproceedings{lemos_sampling-based_2023,
    title = {Sampling-{Based} {Accuracy} {Testing} of {Posterior} {Estimators} for {General} {Inference}},
    url = {https://proceedings.mlr.press/v202/lemos23a.html},
    abstract = {Parameter inference, i.e. inferring the posterior distribution of the parameters of a statistical model given some data, is a central problem to many scientific disciplines. Posterior inference with generative models is an alternative to methods such as Markov Chain Monte Carlo, both for likelihood-based and simulation-based inference. However, assessing the accuracy of posteriors encoded in generative models is not straightforward. In this paper, we introduce "Tests of Accuracy with Random Points" (TARP) coverage testing as a method to estimate coverage probabilities of generative posterior estimators. Our method differs from previously-existing coverage-based methods, which require posterior evaluations. We prove that our approach is necessary and sufficient to show that a posterior estimator is accurate. We demonstrate the method on a variety of synthetic examples, and show that TARP can be used to test the results of posterior inference analyses in high-dimensional spaces. We also show that our method can detect inaccurate inferences in cases where existing methods fail.},
    language = {en},
    urldate = {2024-10-17},
    booktitle = {Proceedings of the 40th {International} {Conference} on {Machine} {Learning}},
    publisher = {PMLR},
    author = {Lemos, Pablo and Coogan, Adam and Hezaveh, Yashar and Perreault-Levasseur, Laurence},
    month = jul,
    year = {2023},
    note = {ISSN: 2640-3498},
    keywords = {cited, done},
    pages = {19256--19273},
}
@article{linhart_l-c2st_2023,
    title = {L-{C2ST}: {Local} {Diagnostics} for {Posterior} {Approximations} in {Simulation}-{Based} {Inference}},
    volume = {36},
    shorttitle = {L-{C2ST}},
    url = {https://proceedings.neurips.cc/paper_files/paper/2023/hash/b0313c2f4501a81d0e0d4a1e8fbf4995-Abstract-Conference.html},
    language = {en},
    urldate = {2024-10-18},
    journal = {Advances in Neural Information Processing Systems},
    author = {Linhart, Julia and Gramfort, Alexandre and Rodrigues, Pedro},
    month = dec,
    year = {2023},
    keywords = {cited, done},
    pages = {56384--56410},
}
@inproceedings{cheng_club_2020,
    title = {{CLUB}: {A} {Contrastive} {Log}-ratio {Upper} {Bound} of {Mutual} {Information}},
    shorttitle = {{CLUB}},
    url = {https://proceedings.mlr.press/v119/cheng20b.html},
    abstract = {Mutual information (MI) minimization has gained considerable interests in various machine learning tasks. However, estimating and minimizing MI in high-dimensional spaces remains a challenging problem, especially when only samples, rather than distribution forms, are accessible. Previous works mainly focus on MI lower bound approximation, which is not applicable to MI minimization problems. In this paper, we propose a novel Contrastive Log-ratio Upper Bound (CLUB) of mutual information. We provide a theoretical analysis of the properties of CLUB and its variational approximation. Based on this upper bound, we introduce a MI minimization training scheme and further accelerate it with a negative sampling strategy. Simulation studies on Gaussian distributions show the reliable estimation ability of CLUB. Real-world MI minimization experiments, including domain adaptation and information bottleneck, demonstrate the effectiveness of the proposed method. The code is at https://github.com/Linear95/CLUB.},
    language = {en},
    urldate = {2025-11-20},
    booktitle = {Proceedings of the 37th {International} {Conference} on {Machine} {Learning}},
    publisher = {PMLR},
    author = {Cheng, Pengyu and Hao, Weituo and Dai, Shuyang and Liu, Jiachang and Gan, Zhe and Carin, Lawrence},
    month = nov,
    year = {2020},
    note = {ISSN: 2640-3498},
    pages = {1779--1788},
}
@article{kleijn_misspecification_2006,
    title = {Misspecification in infinite-dimensional {Bayesian} statistics},
    volume = {34},
    issn = {0090-5364},
    url = {https://projecteuclid.org/journals/annals-of-statistics/volume-34/issue-2/Misspecification-in-infinite-dimensional-Bayesian-statistics/10.1214/009053606000000029.full},
    doi = {10.1214/009053606000000029},
    abstract = {We consider the asymptotic behavior of posterior distributions if the model is misspecified. Given a prior distribution and a random sample from a distribution P 0 , which may not be in the support of the prior, we show that the posterior concentrates its mass near the points in the support of the prior that minimize the Kullback-Leibler divergence with respect to P 0 . An entropy condition and a prior-mass condition determine the rate of convergence. The method is applied to several examples, with special interest for infinite-dimensional models. These include Gaussian mixtures, nonparametric regression and parametric models.},
    number = {2},
    urldate = {2025-11-20},
    journal = {The Annals of Statistics},
    author = {Kleijn, B. J. K. and Van Der Vaart, A. W.},
    month = apr,
    year = {2006},
}
@article{bissiri_general_2016,
    title = {A {General} {Framework} for {Updating} {Belief} {Distributions}},
    volume = {78},
    copyright = {http://creativecommons.org/licenses/by/4.0/},
    issn = {1369-7412, 1467-9868},
    url = {https://academic.oup.com/jrsssb/article/78/5/1103/7040623},
    doi = {10.1111/rssb.12158},
    abstract = {Summary
            We propose a framework for general Bayesian inference. We argue that a valid update of a prior belief distribution to a posterior can be made for parameters which are connected to observations through a loss function rather than the traditional likelihood function, which is recovered as a special case. Modern application areas make it increasingly challenging for Bayesians to attempt to model the true data-generating mechanism. For instance, when the object of interest is low dimensional, such as a mean or median, it is cumbersome to have to achieve this via a complete model for the whole data distribution. More importantly, there are settings where the parameter of interest does not directly index a family of density functions and thus the Bayesian approach to learning about such parameters is currently regarded as problematic. Our framework uses loss functions to connect information in the data to functionals of interest. The updating of beliefs then follows from a decision theoretic approach involving cumulative loss functions. Importantly, the procedure coincides with Bayesian updating when a true likelihood is known yet provides coherent subjective inference in much more general settings. Connections to other inference frameworks are highlighted.},
    language = {en},
    number = {5},
    urldate = {2025-11-20},
    journal = {Journal of the Royal Statistical Society Series B: Statistical Methodology},
    author = {Bissiri, P. G. and Holmes, C. C. and Walker, S. G.},
    month = nov,
    year = {2016},
    pages = {1103--1130},
}
@inproceedings{koers_misspecified_2023,
    title = {Misspecified {Bernstein}-{Von} {Mises} theorem for hierarchical models},
    url = {https://www.semanticscholar.org/paper/Misspecified-Bernstein-Von-Mises-theorem-for-models-Koers-Szab'o/015fb149f414f9d0f6c9d60634dc21aba00d0a23},
    abstract = {We derive a Bernstein von-Mises theorem in the context of misspecified, non-i.i.d., hierarchical models parametrized by a finite-dimensional parameter of interest. We apply our results to hierarchical models containing non-linear operators, including the squared integral operator, and PDE-constrained inverse problems. More specifically, we consider the elliptic, time-independent Schr{\textbackslash}"odinger equation with parametric boundary condition and general parabolic PDEs with parametric potential and boundary constraints. Our theoretical results are complemented with numerical analysis on synthetic data sets, considering both the square integral operator and the Schr{\textbackslash}"odinger equation.},
    urldate = {2025-11-21},
    author = {Koers, Geerten and Szab'o, Botond and Vaart, A.},
    month = aug,
    year = {2023},
}
@inproceedings{belomestny_bernsteinvon_2023,
    address = {Cham},
    title = {Bernstein–von {Mises} {Theorem} and {Misspecified} {Models}: {A} {Review}},
    volume = {425},
    isbn = {978-3-031-30113-1 978-3-031-30114-8},
    shorttitle = {Bernstein–von {Mises} {Theorem} and {Misspecified} {Models}},
    url = {https://link.springer.com/10.1007/978-3-031-30114-8_10},
    doi = {10.1007/978-3-031-30114-8_10},
    abstract = {This is a review of asymptotic and non-asymptotic behaviour of Bayesian methods under model specification. In particular we focus on consistency, i.e. convergence of the posterior distribution to the point mass at the best parametric approximation to the true model, and conditions for it to be locally Gaussian around this point. For well specified regular models, variance of the Gaussian approximation coincides with the Fisher information, making Bayesian inference asymptotically efficient. In this review, we discuss how this is affected by model misspecification. We also discuss approaches to adjust Bayesian inference to make it asymptotically efficient under model misspecification.},
    language = {en},
    urldate = {2025-11-21},
    publisher = {Springer International Publishing},
    author = {Bochkina, Natalia},
    editor = {Belomestny, Denis and Butucea, Cristina and Mammen, Enno and Moulines, Eric and Reiß, Markus and Ulyanov, Vladimir V.},
    year = {2023},
    doi = {10.1007/978-3-031-30114-8_10},
    note = {Book Title: Foundations of Modern Statistics
Series Title: Springer Proceedings in Mathematics \& Statistics},
    pages = {355--380},
}
@article{shalizi_dynamics_2009,
    title = {Dynamics of {Bayesian} updating with dependent data and misspecified models},
    volume = {3},
    issn = {1935-7524, 1935-7524},
    url = {https://projecteuclid.org/journals/electronic-journal-of-statistics/volume-3/issue-none/Dynamics-of-Bayesian-updating-with-dependent-data-and-misspecified-models/10.1214/09-EJS485.full},
    doi = {10.1214/09-EJS485},
    abstract = {Much is now known about the consistency of Bayesian updating on infinite-dimensional parameter spaces with independent or Markovian data. Necessary conditions for consistency include the prior putting enough weight on the correct neighborhoods of the data-generating distribution; various sufficient conditions further restrict the prior in ways analogous to capacity control in frequentist nonparametrics. The asymptotics of Bayesian updating with mis-specified models or priors, or non-Markovian data, are far less well explored. Here I establish sufficient conditions for posterior convergence when all hypotheses are wrong, and the data have complex dependencies. The main dynamical assumption is the asymptotic equipartition (Shannon-McMillan-Breiman) property of information theory. This, along with Egorov’s Theorem on uniform convergence, lets me build a sieve-like structure for the prior. The main statistical assumption, also a form of capacity control, concerns the compatibility of the prior and the data-generating process, controlling the fluctuations in the log-likelihood when averaged over the sieve-like sets. In addition to posterior convergence, I derive a kind of large deviations principle for the posterior measure, extending in some cases to rates of convergence, and discuss the advantages of predicting using a combination of models known to be wrong. An appendix sketches connections between these results and the replicator dynamics of evolutionary theory.},
    number = {none},
    urldate = {2025-11-21},
    journal = {Electronic Journal of Statistics},
    author = {Shalizi, Cosma Rohilla},
    month = jan,
    year = {2009},
    note = {Publisher: Institute of Mathematical Statistics and Bernoulli Society},
    keywords = {60F10, 62C10, 62G20, 62M05, 62M09, 92D15, 94A17, Asymptotic equipartition, Bayesian consistency, Bayesian nonparametrics, Egorov’s theorem, large deviations, posterior convergence, replicator dynamics, sofic systems},
    pages = {1039--1074},
}
@article{grunwald_inconsistency_2017,
    title = {Inconsistency of {Bayesian} {Inference} for {Misspecified} {Linear} {Models}, and a {Proposal} for {Repairing} {It}},
    volume = {12},
    issn = {1936-0975, 1931-6690},
    url = {https://projecteuclid.org/journals/bayesian-analysis/volume-12/issue-4/Inconsistency-of-Bayesian-Inference-for-Misspecified-Linear-Models-and-a/10.1214/17-BA1085.full},
    doi = {10.1214/17-BA1085},
    abstract = {We empirically show that Bayesian inference can be inconsistent under misspecification in simple linear regression problems, both in a model averaging/selection and in a Bayesian ridge regression setting. We use the standard linear model, which assumes homoskedasticity, whereas the data are heteroskedastic (though, significantly, there are no outliers). As sample size increases, the posterior puts its mass on worse and worse models of ever higher dimension. This is caused by hypercompression, the phenomenon that the posterior puts its mass on distributions that have much larger KL divergence from the ground truth than their average, i.e. the Bayes predictive distribution. To remedy the problem, we equip the likelihood in Bayes’ theorem with an exponent called the learning rate, and we propose the SafeBayesian method to learn the learning rate from the data. SafeBayes tends to select small learning rates, and regularizes more, as soon as hypercompression takes place. Its results on our data are quite encouraging.},
    number = {4},
    urldate = {2025-11-21},
    journal = {Bayesian Analysis},
    author = {Grünwald, Peter and Ommen, Thijs van},
    month = dec,
    year = {2017},
    note = {Publisher: International Society for Bayesian Analysis},
    pages = {1069--1103},
}
@misc{guedj_primer_2019,
    title = {A {Primer} on {PAC}-{Bayesian} {Learning}},
    url = {https://arxiv.org/abs/1901.05353v3},
    abstract = {Generalised Bayesian learning algorithms are increasingly popular in machine learning, due to their PAC generalisation properties and flexibility. The present paper aims at providing a self-contained survey on the resulting PAC-Bayes framework and some of its main theoretical and algorithmic developments.},
    language = {en},
    urldate = {2025-11-21},
    journal = {arXiv.org},
    author = {Guedj, Benjamin},
    month = jan,
    year = {2019},
}
@article{Tishby2015DeepLearningInformation,
    title = {Deep learning and the information bottleneck principle},
    url = {http://arxiv.org/abs/1503.02406},
    author = {Tishby, Naftali and Zaslavsky, Noga},
    month = mar,
    year = {2015},
    note = {arXiv: 1503.02406 [cs.LG]
tex.arxivid: 1503.02406},
}
@misc{tishby_information_2000,
    title = {The information bottleneck method},
    url = {https://arxiv.org/abs/physics/0004057v1},
    abstract = {We define the relevant information in a signal \$x{\textbackslash}in X\$ as being the information that this signal provides about another signal \$y{\textbackslash}in {\textbackslash}Y\$. Examples include the information that face images provide about the names of the people portrayed, or the information that speech sounds provide about the words spoken. Understanding the signal \$x\$ requires more than just predicting \$y\$, it also requires specifying which features of \${\textbackslash}X\$ play a role in the prediction. We formalize this problem as that of finding a short code for \${\textbackslash}X\$ that preserves the maximum information about \${\textbackslash}Y\$. That is, we squeeze the information that \${\textbackslash}X\$ provides about \${\textbackslash}Y\$ through a `bottleneck' formed by a limited set of codewords \${\textbackslash}tX\$. This constrained optimization problem can be seen as a generalization of rate distortion theory in which the distortion measure \$d(x,{\textbackslash}x)\$ emerges from the joint statistics of \${\textbackslash}X\$ and \${\textbackslash}Y\$. This approach yields an exact set of self consistent equations for the coding rules \$X {\textbackslash}to {\textbackslash}tX\$ and \${\textbackslash}tX {\textbackslash}to {\textbackslash}Y\$. Solutions to these equations can be found by a convergent re-estimation method that generalizes the Blahut-Arimoto algorithm. Our variational principle provides a surprisingly rich framework for discussing a variety of problems in signal processing and learning, as will be described in detail elsewhere.},
    language = {en},
    urldate = {2025-11-21},
    journal = {arXiv.org},
    author = {Tishby, Naftali and Pereira, Fernando C. and Bialek, William},
    month = apr,
    year = {2000},
}
@misc{li_invariant_2022,
    title = {Invariant {Information} {Bottleneck} for {Domain} {Generalization}},
    url = {http://arxiv.org/abs/2106.06333},
    doi = {10.48550/arXiv.2106.06333},
    abstract = {Invariant risk minimization (IRM) has recently emerged as a promising alternative for domain generalization. Nevertheless, the loss function is difficult to optimize for nonlinear classifiers and the original optimization objective could fail when pseudo-invariant features and geometric skews exist. Inspired by IRM, in this paper we propose a novel formulation for domain generalization, dubbed invariant information bottleneck (IIB). IIB aims at minimizing invariant risks for nonlinear classifiers and simultaneously mitigating the impact of pseudo-invariant features and geometric skews. Specifically, we first present a novel formulation for invariant causal prediction via mutual information. Then we adopt the variational formulation of the mutual information to develop a tractable loss function for nonlinear classifiers. To overcome the failure modes of IRM, we propose to minimize the mutual information between the inputs and the corresponding representations. IIB significantly outperforms IRM on synthetic datasets, where the pseudo-invariant features and geometric skews occur, showing the effectiveness of proposed formulation in overcoming failure modes of IRM. Furthermore, experiments on DomainBed show that IIB outperforms \$13\$ baselines by \$0.9{\textbackslash}\%\$ on average across \$7\$ real datasets.},
    urldate = {2025-05-08},
    publisher = {arXiv},
    author = {Li, Bo and Shen, Yifei and Wang, Yezhen and Zhu, Wenzhen and Reed, Colorado J. and Zhang, Jun and Li, Dongsheng and Keutzer, Kurt and Zhao, Han},
    month = mar,
    year = {2022},
    note = {arXiv:2106.06333 [cs]},
    keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
}
@inproceedings{zemel_learning_2013,
    title = {Learning {Fair} {Representations}},
    url = {https://proceedings.mlr.press/v28/zemel13.html},
    abstract = {We propose a learning algorithm for fair classification that achieves both group fairness (the proportion of members in a protected group receiving positive classification is identical to the proportion in the population as a  whole), and individual fairness (similar individuals should be treated similarly).  We formulate fairness as an optimization problem of finding a  good representation of the data with two competing goals: to encode the data as well as possible, while simultaneously obfuscating any information about membership in the protected group.  We show positive results of our algorithm relative to other known techniques, on three datasets.  Moreover, we demonstrate several advantages to our approach.  First, our intermediate representation can be used for other classification tasks (i.e., transfer  learning is possible); secondly, we take a step toward learning a distance metric which can find important dimensions of the data for classification.},
    language = {en},
    urldate = {2025-11-21},
    booktitle = {Proceedings of the 30th {International} {Conference} on {Machine} {Learning}},
    publisher = {PMLR},
    author = {Zemel, Rich and Wu, Yu and Swersky, Kevin and Pitassi, Toni and Dwork, Cynthia},
    month = may,
    year = {2013},
    note = {ISSN: 1938-7228},
    pages = {325--333},
}
@article{zhao_fundamental_2020,
    title = {Fundamental {Limits} and {Tradeoffs} in {Invariant} {Representation} {Learning}},
    url = {https://www.semanticscholar.org/paper/Fundamental-Limits-and-Tradeoffs-in-Invariant-Zhao-Dan/531beffcfca278108d8f89e1f9f5ed474907aa2d},
    abstract = {A wide range of machine learning applications such as privacy-preserving learning, algorithmic fairness, and domain adaptation/generalization among others, involve learning invariant representations of the data that aim to achieve two competing goals: (a) maximize information or accuracy with respect to a target response, and (b) maximize invariance or independence with respect to a set of protected features (e.g., for fairness, privacy, etc). Despite their wide applicability, theoretical understanding of the optimal tradeoffs -- with respect to accuracy, and invariance -- achievable by invariant representations is still severely lacking. In this paper, we provide an information theoretic analysis of such tradeoffs under both classification and regression settings. More precisely, we provide a geometric characterization of the accuracy and invariance achievable by any representation of the data; we term this feasible region the information plane. We provide an inner bound for this feasible region for the classification case, and an exact characterization for the regression case, which allows us to either bound or exactly characterize the Pareto optimal frontier between accuracy and invariance. Although our contributions are mainly theoretical, a key practical application of our results is in certifying the potential sub-optimality of any given representation learning algorithm for either classification or regression tasks. Our results shed new light on the fundamental interplay between accuracy and invariance, and may be useful in guiding the design of future representation learning algorithms.},
    urldate = {2025-11-20},
    journal = {J. Mach. Learn. Res.},
    author = {Zhao, Han and Dan, Chen and Aragam, Bryon and Jaakkola, T. and Gordon, Geoffrey J. and Ravikumar, Pradeep},
    month = dec,
    year = {2020},
}
@misc{arjovsky_invariant_2020,
    title = {Invariant {Risk} {Minimization}},
    url = {http://arxiv.org/abs/1907.02893},
    doi = {10.48550/arXiv.1907.02893},
    abstract = {We introduce Invariant Risk Minimization (IRM), a learning paradigm to estimate invariant correlations across multiple training distributions. To achieve this goal, IRM learns a data representation such that the optimal classifier, on top of that data representation, matches for all training distributions. Through theory and experiments, we show how the invariances learned by IRM relate to the causal structures governing the data and enable out-of-distribution generalization.},
    urldate = {2025-11-21},
    publisher = {arXiv},
    author = {Arjovsky, Martin and Bottou, Léon and Gulrajani, Ishaan and Lopez-Paz, David},
    month = mar,
    year = {2020},
    note = {arXiv:1907.02893 [stat]},
    keywords = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning, Statistics - Machine Learning},
}
@article{modrak_simulation-based_2025,
    title = {Simulation-{Based} {Calibration} {Checking} for {Bayesian} {Computation}: {The} {Choice} of {Test} {Quantities} {Shapes} {Sensitivity}},
    volume = {20},
    issn = {1936-0975},
    shorttitle = {Simulation-{Based} {Calibration} {Checking} for {Bayesian} {Computation}},
    url = {https://projecteuclid.org/journals/bayesian-analysis/volume-20/issue-2/Simulation-Based-Calibration-Checking-for-Bayesian-Computation--The-Choice/10.1214/23-BA1404.full},
    doi = {10.1214/23-BA1404},
    abstract = {Simulation-based calibration checking (SBC) is a practical method to validate computationally-derived posterior distributions or their approximations. In this paper, we introduce a new variant of SBC to alleviate several known problems. Our variant allows the user to in principle detect any possible issue with the posterior, while previously reported implementations could never detect large classes of problems including when the posterior is equal to the prior. This is made possible by including additional data-dependent test quantities when running SBC. We argue and demonstrate that the joint likelihood of the data is an especially useful test quantity. Some other types of test quantities and their theoretical and practical benefits are also investigated. We provide theoretical analysis of SBC, thereby providing a more complete understanding of the underlying statistical mechanisms. We also bring attention to a relatively common mistake in the literature and clarify the difference between SBC and checks based on the data-averaged posterior. We support our recommendations with numerical case studies on a multivariate normal example and a case study in implementing an ordered simplex data type for use with Hamiltonian Monte Carlo. The SBC variant introduced in this paper is implemented in the SBC R package.},
    number = {2},
    urldate = {2025-11-21},
    journal = {Bayesian Analysis},
    author = {Modrák, Martin and Moon, Angie H. and Kim, Shinyoung and Bürkner, Paul and Huurre, Niko and Faltejsková, Kateřina and Gelman, Andrew and Vehtari, Aki},
    month = jun,
    year = {2025},
}