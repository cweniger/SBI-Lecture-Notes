\section{Gradient-Based Techniques}
\label{sec:gradient_based_techniques}

\subsection{Flow Matching}

An alternative training strategy for continuous normalizing flows, as discussed in Sec.~\ref{sec:core_methods_flows}, was introduced in \cite{lipman_flow_2023} for generative models and adopted to the conditional structures of simulation-based inference in \cite{wildberger_flow_2023}. The advantage is that it does not require integration of ODEs during training, only at the evaluation stage. We will here briefly discuss the mechanisms and connection with NPE.

The goal is again to transform parameters $\btheta$ drawn from a simple distribution $p_0(\btheta)$ into parameters drawn from the posterior $p(\btheta \mid \bx)$, but following the ODE
\[
\frac{d}{dt}\btheta_t = \mathbf{v}_\phi(\btheta_t, \bx, t) \quad \text{with} \quad \btheta_0 \sim p_0(\btheta_0),
\]
where $\mathbf{v}_\phi$ is a learnable velocity field that is data dependent.

The continuity equation implies that the underlying density field changes like
\[
\frac{d}{dt} \log q_{\phi, t}(\btheta_t \mid \mathbf{x}, t) = -\nabla_{\btheta} \cdot \mathbf{v}_\phi(\btheta_t, \bx, t).
\]
The training goal is that the endpoint at $t=1$ approximates the full posterior:
\[
q_\phi(\btheta \mid \bx) \equiv q_{\phi,1}(\btheta_{1} \mid \bx, 1) \approx p(\btheta \mid \bx).
\]

Instead of training via maximum likelihood, like CNFs, we directly train the velocity field. To this end, one needs to explicitly define a path that connects the simple with the target distribution. There is quite some flexibility in doing this. It can be done by defining through the integral
\[
p_t(\btheta_t \mid \bx) = \int d\btheta\; p_t(\btheta_t \mid \btheta_1 = \btheta) p(\btheta \mid \bx)
\]
such that $p_0(\btheta_0 \mid \btheta_1) = p_0(\btheta_0)$ and $p_1(\btheta_1 \mid \bx) \simeq p(\btheta =\btheta_1\mid \bx)$.

Here we introduced a distortion function $p_t(\btheta_t \mid \btheta_1)$ that takes samples from the final distribution (the posterior) and redistributes them at some earlier time $t<1$. A convenient ansatz is to define a distortion function 
\[
p_t(\btheta_t \mid \btheta_1 ) = \mathcal{N}(\btheta_t \mid \alpha_t \btheta_1, \sigma_t^2 \mathbf{I})
\]
which rescales $\btheta_1$.

After defining the path, the remaining challenge is to identify the velocity field that would lead to this probability distribution path. This is generally very difficult. For the above construction, however, \cite{lipman_flow_2023} showed that knowing the vector field that generates the conditional distribution $p_t(\btheta_t \mid \btheta_1)$ is enough to know the vector field for the full one. It is not immediately obvious, but one can find through application of the continuity equation that
\[
\mathbf{u}(\btheta_t, \bx) = \mathbb{E}_{\btheta_1 \sim p(\btheta_1 \mid \btheta_t, \bx)} [\mathbf{u}(\btheta_t \mid \btheta_1)].
\]
The target velocity field is given by:
$$
\mathbf{u}(\btheta \mid \btheta_1) = \mathbb{E}[\alpha'_t \btheta_1 + \sigma'_t \boldsymbol{\varepsilon} \mid \btheta_t = \btheta]
$$

This leads to the loss function
\[
\mathcal{L}_{\text{FMPE}} = \mathbb{E}_{
t\sim \mathcal{U}(0, 1),
\btheta_1 \sim p(\btheta \mid \bx),
\btheta_t \sim p(\btheta_t \mid \btheta_1)
}
\|\mathbf{v}_\phi(\btheta_t, \bx, t) - \mathbf{u}(\btheta_t \mid \btheta_1)
\|^2.
\]

\cite{wildberger_flow_2023} show that under specific regularity conditions, there is the bound
\[
D_{\text{KL}}(p(\btheta \mid \bx) \, \| \, q_\phi(\btheta \mid \bx) ) < C \cdot \mathcal{L}_{\text{FMPE}}
\]
for some constant $C>0$. This suggests that much of the logic and empirical aspects of NPE also apply to flow matching. Like for NPE, one can train end-to-end embedding networks, evaluate log density without much cost (requires integration over the trained vector field), and perform fast sampling through forward integration.


\subsection{Score Matching}

To handle more complex distributions, stochasticity can be introduced via:
$$
d\mathbf{x} = \mathbf{u}(\mathbf{x}, t)dt + g(t)d\mathbf{W}
$$
With the standard assumption $g(t)^2 = 2\sigma_t\sigma'_t$, the drift term becomes:
$$
\mathbf{u}_{\text{diff}}(\mathbf{x}, t) = \frac{\alpha'_t}{\alpha_t}\mathbf{x} - \frac{\sigma'_t}{\sigma_t}\mathbb{E}[\boldsymbol{\varepsilon} | \mathbf{x}_t = \mathbf{x}]
$$
This shows that training to predict the noise $\boldsymbol{\varepsilon}$ suffices:
\begin{equation}
   \mathcal{L} = \mathbb{E}_{t,\mathbf{x}_1,\boldsymbol{\varepsilon}} \left[\left\|\boldsymbol{\varepsilon}_\theta(\mathbf{x}_t, t) - \boldsymbol{\varepsilon}\right\|^2\right]
\end{equation}
Sampling is performed by solving the reverse SDE from noise to data.


Using the continuity equation, the log-density evolves along trajectories according to the instantaneous change-of-variables formula (\textit{i.e.}, its infinitesimal change in time along the flow),
\cw{TODO: Restructure text such that the two ODEs are shown together, so that the connection is clear}
allowing computation of the exact likelihood via integration. CNFs enable flexible modeling of complex distributions while maintaining exact and tractable likelihoods. The dynamics \( f_\phi \) are typically parameterized by dense neural networks (MLPs) and trained by maximizing the likelihood over observed data using ODE solvers with automatic differentiation.

- dz/dt = f & d/dt log p = grad f
- loss on p(x, t=T)

- 

\medskip

\cw{TODO: Need to talk about conditional flows!!!}

\cw{TODO: Fine for now, but should be more evolved in the future}
A further generalization of continuous flows introduces stochasticity into the transformation process. Rather than following deterministic dynamics, the latent variable evolves according to a stochastic differential equation, allowing the model to inject noise and capture richer, more multimodal distributions. This extension leads to the class of \emph{diffusion models}, which have recently gained prominence in generative modeling.

In contrast to normalizing flows and CNFs---where the transformation is learned end-to-end---diffusion models define a fixed forward process that gradually corrupts data with noise, and then learn to reverse this process. The transformation is thus guided: the forward dynamics are predefined, and the learning focuses on inverting them. While diffusion models offer powerful generative capabilities, they differ fundamentally from the flow-based methods discussed here, and we will not cover them in detail.



\subsection{Denoising Score Matching}

%\cw{TODOREF - Score-based}

The Fisher divergence, Eq.~\eqref{eqn:FisherDiv}, only depends on the score function, and can in principle be used to build a simulation-based inference algorithm by focusing on the loss function
%
\begin{equation}
    \bbE_{p(x)} [D_F(q(\mathbf z \mid \mathbf x) \mid\mid  p(\mathbf z\mid \mathbf x))]
\end{equation}
%
The only thing we really did w.r.t.~Eq.~\eqref{eqn:DKL} was to replace the forward KL divergence with the Fisher divergence.  If we were able to minimize that loss, we would learn the score function of the posterior $s = \nabla_\bz \log q(\bz \mid \bx)$, which gives us access to an energy-based model of the posterior.
%
An immediate challenge for this approach is that the score function of the true posterior $p(\bz \mid \bx)$ is not known.  

\medskip

We can make however use of the following general observation.  Let us consider a noisy target model, where the implicit distribution $q(\bz)$ got convolved with some noise distribution $p(\tilde \bz \mid \bz)$.  
%
\begin{equation}
p(\tilde{\mathbf{z}})=\int d\bz\; p(\tilde{\mathbf{z}} \mid \mathbf{z}) q(\mathbf{z})\;.
\end{equation}
%
A typical example is $\tilde \bz = \bz + \boldsymbol\epsilon$, where $\boldsymbol \epsilon \sim \mathcal{N}(0, \sigma^2 \mathbb{1})$. In that case, the conditional noise distribution and its score function are tractable, $p(\tilde \bz \mid \bz) = \mathcal{N}(\tilde \bz; \bz, \sigma^2 \mathbb{1})$.

Importantly, one can now show, using integration by parts and re-arranging terms that are not directly dependent on $\phi$, that the Fisher divergence between the noisy target and a variational approximator is given by
%
\begin{equation}
\begin{aligned}
D_F\left(p(\tilde{\mathbf{z}}) \| q_{\phi}(\tilde{\mathbf{z}})\right) & =\mathbb{E}_{p(\tilde{\mathbf{z}})}\left[\frac{1}{2}\left\|\nabla_{\mathbf{z}} \log p(\tilde{\mathbf{z}})-\nabla_{\mathbf{z}} \log q_{\phi}(\tilde{\mathbf{z}})\right\|_2^2\right] \\
& =\mathbb{E}_{p(\tilde \bz \mid \bz) q(\mathbf{z} )}\left[\frac{1}{2}\left\|\nabla_{\mathbf{z}} \log p(\tilde{\mathbf{z}} \mid \mathbf{z})-\nabla_{\mathbf{z}} \log q_{\phi}(\tilde{\mathbf{z}})\right\|_2^2\right]+\text { constant }\;.
\end{aligned}
\end{equation}
%
In the last step, the intractable gradient $\nabla_\bx \log p(\tilde \bx)$ got replaced by the tractable gradient of $\nabla_\bx \log p(\tilde \bx \mid \bx)$.  Samples are jointly performed over the noisy-free and the noisy distribution.

\medskip

Using the above relation, we can now formulate a target for estimating the (score of the) posterior $p(\bz \mid \bx)$ with denoising score matching. We do this by replacing all distributions in the above equations by data-conditioned distributions, and averaging over data relatizations.
%
\begin{equation}
    \mathcal{L} = 
    \bbE_{p(\tilde \bz \mid \bz) p(\bx \mid \bz) p(\bz)}
    \left[
    \frac12
\left\|\nabla_{\mathbf{z}} \log p(\tilde{\mathbf{z}} \mid \mathbf{z})-\nabla_{\mathbf{z}} \log q_{\phi}(\tilde{\mathbf{z}} \mid \bx)\right\|_2^2
    \right]
\end{equation}
%
Minimizing that loss trains now a the score function of the posterior for the noise-added parameters $\tilde \bz$,
\begin{equation}
    \nabla_\bz \log q_\phi(\tilde \bz \mid \bx)
    \approx
    \nabla_\bz \log p(\tilde \bz \mid \bx)
\end{equation}
%
In the limit of small enough noise variance $\sigma^2$, the resulting score function will reasonably well approximate the true posterior score.

\medskip

Some additional observations.
\begin{itemize}
    \item One can show that the above optimization target becomes high variance in the limit of small $\sigma$.
    \item In contrast to neural ratio estimation, there are no constraints on the partition function $Z$.
    \item ...
\end{itemize}

\subsection{Diffusion Denoising Probabilistc Models}

\begin{equation}
\mathrm{d} \mathbf{x}_t=-\frac{1}{2} \beta(t) \mathbf{x}_t \mathrm{~d} t+\sqrt{\beta(t)} \mathrm{d} \boldsymbol{\omega}_t
\end{equation}

\begin{equation}
q_t\left(\mathbf{x}_t \mid \mathbf{x}_0\right)=\mathcal{N}\left(\mathbf{x}_t ; \gamma_t \mathbf{x}_0, \sigma_t^2 \mathbf{I}\right)
\end{equation}

\begin{equation}
\mathrm{d} \mathbf{x}_t=\left[-\frac{1}{2} \beta(t) \mathbf{x}_t-\beta(t) \nabla_{\mathbf{x}_t} \log q_t\left(\mathbf{x}_t\right)\right] \mathrm{d} t+\sqrt{\beta(t)} \mathrm{d} \overline{\boldsymbol{\omega}}_t
\end{equation}

\begin{equation}
\mathcal{L}[\boldsymbol{\theta}] =
\mathbb{E}_{t \sim \mathcal{U}(0, T)} \mathbb{E}_{\mathbf{x}_0 \sim q_0\left(\mathbf{x}_0\right)} \mathbb{E}_{\mathbf{x}_t \sim q_t\left(\mathbf{x}_t \mid \mathbf{x}_0\right)}\left\|\mathbf{s}_{\boldsymbol{\theta}}\left(\mathbf{x}_t, t\right)-\nabla_{\mathbf{x}_t} \log q_t\left(\mathbf{x}_t \mid \mathbf{x}_0\right)\right\|_2^2
\end{equation}

\begin{equation}
    \mathcal{L}[\boldsymbol{\theta}] =
    \mathbb{E}_{t \sim \mathcal{U}(0, T)} \mathbb{E}_{\mathbf{x}_0 \sim q_0\left(\mathbf{x}_0\right)} \mathbb{E}_{\boldsymbol{\epsilon} \sim \mathcal{N}(\mathbf{0}, \mathbf{I})} \frac{1}{\sigma_t^2}\left\|\boldsymbol{\epsilon}-\boldsymbol{\epsilon}_{\boldsymbol{\theta}}\left(\mathbf{x}_t, t\right)\right\|_2^2
\end{equation}
